<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8" />

    

    
    <title>DS-Study-Note-9 Gradient Boosting Machine Tree Model(s) | The blog of Blur</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="keywords" content="DataScience,Machine Learning,GBM,XGBoost" />
    
    <meta name="description" content="Gradient Boosting Machine TreeGBMTree stands for Gradient Boosting Machine Tree.">
<meta property="og:type" content="article">
<meta property="og:title" content="DS-Study-Note-9 Gradient Boosting Machine Tree Model(s)">
<meta property="og:url" content="https://umiao.github.io/2022/05/25/DS-Study-Note-9/index.html">
<meta property="og:site_name" content="The blog of Blur">
<meta property="og:description" content="Gradient Boosting Machine TreeGBMTree stands for Gradient Boosting Machine Tree.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://umiao.github.io/2022/05/25/DS-Study-Note-9/theory.jpg">
<meta property="article:published_time" content="2022-05-26T02:54:23.000Z">
<meta property="article:modified_time" content="2022-05-28T22:43:50.842Z">
<meta property="article:author" content="Blur - Shenghui Xu">
<meta property="article:tag" content="DataScience">
<meta property="article:tag" content="Machine Learning">
<meta property="article:tag" content="GBM">
<meta property="article:tag" content="XGBoost">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://umiao.github.io/2022/05/25/DS-Study-Note-9/theory.jpg">
    

    
        <link rel="alternate" href="/" title="The blog of Blur" type="application/atom+xml" />
    

    

    
<link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">

    
<link rel="stylesheet" href="/libs/titillium-web/styles.css">

    
<link rel="stylesheet" href="/libs/source-code-pro/styles.css">


    
<link rel="stylesheet" href="/css/style.css">


    
<script src="/libs/jquery/3.5.0/jquery.min.js"></script>

    
    
        
<link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">

    
    
        
<link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">

    
    
    
    


<meta name="generator" content="Hexo 6.1.0"></head>

<body>
    <div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" class="logo"></a>
                    </h1>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/">Home</a>
                                </li>
                            
                                    <ul class="main-nav-list"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/AI/">AI</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/AI/NLP/">NLP</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Data-Science/">Data Science</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Data-Science/General-Knowledge/">General Knowledge</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Data-Science/SQL/">SQL</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Investment/">Investment</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Job-Search/">Job Search</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Job-Search/Financial-Firm/">Financial Firm</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Job-Search/SQL/">SQL</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Job-Search/Software-Engineering/">Software Engineering</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Productivity/">Productivity</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/UCLA/">UCLA</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/UCLA/Course-Study/">Course Study</a></li></ul></li></ul>
                                
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/about/">About</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
		// ROOT_URL: 'https://umiao.github.io/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>


</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>

        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    <a class="page-title-link" href="/categories/Data-Science/">Data Science</a><i class="icon fa fa-angle-right"></i><a class="page-title-link" href="/categories/Data-Science/General-Knowledge/">General Knowledge</a>
    </h1>
</div>

                        <div class="main-body-content">
                            <article id="post-DS-Study-Note-9" class="article article-single article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        DS-Study-Note-9 Gradient Boosting Machine Tree Model(s)
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2022/05/25/DS-Study-Note-9/" class="article-date">
       <time datetime="2022-05-26T02:54:23.000Z" itemprop="datePublished">2022-05-25</time>
    </a>
  </div>


<div class="article-date">
  <i class="fa fa-calendar-plus-o"></i>
  <a href="/2022/05/25/DS-Study-Note-9/" class="article-date">
     <time datetime="2022-05-28T22:43:50.842Z" itemprop="dateModified">2022-05-28</time>
  </a>
</div>


                

                
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link-link" href="/tags/DataScience/" rel="tag">DataScience</a>, <a class="tag-link-link" href="/tags/GBM/" rel="tag">GBM</a>, <a class="tag-link-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a>, <a class="tag-link-link" href="/tags/XGBoost/" rel="tag">XGBoost</a>
    </div>

                

                

            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            

            

            

            <h1 id="Gradient-Boosting-Machine-Tree"><a href="#Gradient-Boosting-Machine-Tree" class="headerlink" title="Gradient Boosting Machine Tree"></a>Gradient Boosting Machine Tree</h1><p><strong>GBMTree</strong> stands for <strong>Gradient Boosting Machine Tree</strong>.</p>
<span id="more"></span>
<p>The idea is to train multiple serial <strong>weak</strong> learner, while the objective of each learner is to fit the <strong>negative</strong> gradient of the loss function of the previous cumulative model.<br>Thus, after this weak learner is attached, the loss of the new cumulative model shall be maximally reduced. Also, each base (weak) learner can be linearly combined with different weights (so that those learners with higher performance would contribute more to the result). A common implementation of the base learner is Tree Model (<em>e.g.</em>, Decision Tree).</p>
<img src="/2022/05/25/DS-Study-Note-9/theory.jpg" class="" title="ML_note">

<h1 id="Primary-Feature"><a href="#Primary-Feature" class="headerlink" title="Primary Feature"></a>Primary Feature</h1><p>The primary feature of GBM (Gradient Bossting Machine) is that, it conduct <strong>Gradient Descent</strong> in the space of function, instead of the space of model parameters (e.g., Neural Network calculates the gradient of current loss to the model parameters for update).</p>
<p>In Gradient Boosting, in each iteration, a weak learner is generated via <strong>fitting the negative gradient</strong> of loss function to the cumulative model formed by the learners generated before (this means that the previous model is left <strong>unchanged</strong>). Then, the current weak learner is added to the cumulative model to reduce the loss.</p>
<p><strong>Differences</strong>:</p>
<ul>
<li>Gradient descent of the <strong>parameter space</strong> would: use the gradient to update the parameters</li>
<li>Gradient descent of the <strong>function space</strong> would: fit a new function with the gradient</li>
</ul>
<h1 id="Math-Theory"><a href="#Math-Theory" class="headerlink" title="Math Theory"></a>Math Theory</h1><p>Considering we have $n$ training samples $\{x_i, y_i\}$, and the cumulative model in the $k$th round is $F_{k-1}(x)$. Then, the model in the kth round should be:<br>$$ F_k(x) &#x3D; F_{k-1}(x) + arg \min_{h \subset H} Loss(y_i, F_{k-1}(x_i) + h(x_i))   $$<br>where $h(x)$ is the desired weak learner.</p>
<p>In fact, after the $k-1$th round, we can have $\hat y &#x3D; F_{k-1}(x)$ and the loss $Loss(y, \hat y)$. Thus, in order to minimize the model’s loss after introducing the $k$th weak learner, the gradient of this learner $h(x)$ should be negative to the gradient of $F_{k-1}(x)$, so that:<br>$$ Gradient \  h(x) &#x3D; - \frac{\partial Loss(y, \hat y)}{\partial F_{k-1}(x)} $$ </p>
<p>In the actual implementation of this algorithm, a concrete <strong>loss function</strong> and a <strong>learning rate</strong> $\alpha$ should be appointed. The learning rate would be used when updating the model: $F_k(x) &#x3D; F_{k-1}(x) + \alpha h(x)$.<br>We also need to set a boundary condition (number of iteration, minimal improvement &#x2F; difference, etc) to decide when to terminate this algorithm.</p>
<h1 id="GBDT-Gradient-Boosting-Decision-Tree-Algorithm"><a href="#GBDT-Gradient-Boosting-Decision-Tree-Algorithm" class="headerlink" title="GBDT (Gradient Boosting Decision Tree) Algorithm"></a>GBDT (Gradient Boosting Decision Tree) Algorithm</h1><p><strong>GBDT</strong> uses <strong>CART (Classifier And Regression Tree)</strong> as the weak learner.<br>The benefit of such design is that, the Decision Tree itself is unstable, as minor fluctuation of training data can greatly influence the (inference) result (single Decision Tree has <strong>high variance</strong>).</p>
<p>In <strong>Ensemble Learning</strong>, we expect weak classifiers to have <strong>high variance</strong> to achieve <strong>better generalization performance</strong>. Thus, CART is preferred to the more stable weak learners (<em>e.g.</em>, linear regression).</p>
<h1 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h1><ul>
<li><p>In <strong>regression task</strong>, the loss function would be ${(y - F_{k-1}(x))}^2$, then the negative gradient would be $2(y - F_{k-1}(x))$.<br>Thus, we can find the negative gradient simply via $y - F_{k-1}(x)$.</p>
</li>
<li><p>In <strong>classification task</strong>, we aims at fitting the logarithmic probability $\log \frac{p}{1-p}$ with linear model $Wx+b$. The loss function would be <strong>Cross Entropy Loss</strong>: $Loss &#x3D; -y \log p - (1-y)log(1-p)$. Then, we can have<br>$$ F_{k-1}(x) &#x3D; \log\frac{p_{k-1}}{1-p_{k-1}} \Rightarrow p_{k-1} &#x3D; \frac{1}{1 + e^{-F_{k-1}}}  $$<br>$$ Loss &#x3D; -y\log \frac{1}{1 + e^{-F_{k-1}}} - (1-y)\log \frac{e^{-F_{k-1}}}{1 + e^{-F_{k-1}}} $$</p>
<p>  Simplify the expression, we have $Loss &#x3D; (1-y)F_{k-1} + \log(1 + e^{-F_{k-1}})$. $-\frac{\partial Loss}{\partial F_{k-1}} &#x3D; y - p_{k-1}$</p>
</li>
</ul>
<h1 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h1><p><strong>XGBoost</strong> stands for <strong>eXtreme Gradient Boosting</strong>, which is an algorithm based on <strong>GBDT</strong>. It makes multiple improments, including:</p>
<ol>
<li>Apply <strong>second-order Taylor Formula Expansion</strong> to better approximate various loss functions (and faster convergence).</li>
<li>Introduce <strong>regularization term</strong> to prevent overfitting.</li>
<li>Use <strong>Block</strong> to store the structure for parallel processing</li>
</ol>
<h2 id="Math-Theory-1"><a href="#Math-Theory-1" class="headerlink" title="Math Theory"></a>Math Theory</h2><p>The objective function of XGBoost consists of <strong>loss function</strong> and <strong>regularization term</strong>.<br>The objective function can be written as:<br>$$ Loss &#x3D; \sum_{i&#x3D;1}^n l(y_i, \hat y_i) + \sum_{k&#x3D;1}^K \Omega(f_k) $$<br>We have $n$ pairs of training samples and a total of $K$ trees. $\Omega(f_k)$ is the regularization term which measures the model’s complexity.</p>
<p>Since XGB is implemented by Boosting, we also have: $\hat y_i^t &#x3D; \hat y_i^{t-1} + f_t(x_i)$. Here $f_t(x_i)$ is the most recently appended weak learner.</p>
<h3 id="Taylor-Expansion"><a href="#Taylor-Expansion" class="headerlink" title="Taylor Expansion"></a>Taylor Expansion</h3><p>We already know that $f(x) \approx f(x_0) + f’(x_0)(x - x_0) + \frac{f’’(x_0)}{2}(x - x_0)^2$.<br>Then, let $l(x) &#x3D; l(y_i, x)$, find the 2nd order Taylor Expansion at $x_0$, we can have $l(y_i, x) \approx l(y_i, x_0) + l’(y_i, x_0)(x - x_0) + \frac{l’’(y_i, x_0)}{2}(x - x_0)^2$.<br>Similarly, we have $l(y_i, x) \approx l(y_i, \hat y_i^{t-1}) + l’(y_i, \hat y_i^{t-1})(x - \hat y_i^{t-1}) + \frac{l’’(y_i, \hat y_i^{t-1})}{2}(x - \hat y_i^{t-1})^2$.</p>
<p>Note that we have $x &#x3D; \hat y_i^{t-1} + f_t(x_i)$, denote $g_i &#x3D; l’(y_i, \hat y_i^{t-1})$, $h_i &#x3D; l’’(y_i, \hat y_i^{t-1})$, we have:<br>$$ l(y_i, \hat y_i^{t-1} + f_t(x_i)) \approx  l(y_i, \hat y_i^{t-1}) + g_if_t(x_i) + \frac{h_i}{2}f_t^2(x_i)$$<br>Here we finish the derivation.</p>
<h3 id="Unfold-regularization-term"><a href="#Unfold-regularization-term" class="headerlink" title="Unfold regularization term"></a>Unfold regularization term</h3><p>Note that $l(y_i, \hat y_i^{t-1})$ is a constant, we can simply remove it. Also, we unfold the regularization term $\sum_{k&#x3D;1}^K \Omega(f_k) &#x3D; \Omega(f_t) + \sum_{k&#x3D;1}^{t-1}\Omega(f_k)$. The structure of the previous $t-1$ trees would not change, thus we can view their sum as a constant and remove, to have the polished loss function:<br>$$ {Loss}^t &#x3D; \sum_i^n[g_if_t(x_i) + \frac{h_i}{2}f_t^2(x_i)] + \Omega(f_t) $$</p>
<h3 id="Organize-the-objective-function"><a href="#Organize-the-objective-function" class="headerlink" title="Organize the objective function"></a>Organize the objective function</h3><ol>
<li><p>In order to define a Tree, we need the leave nodes’ <strong>weight vector</strong> $\omega \subset R^T$ and the <strong>mapping relationship</strong> $q: R^d \rightarrow 1,2,…,T$, T is the number of the leave nodes. Thus, we can express a tree as $f_t(x) &#x3D; \omega_{q(x)}$.</p>
</li>
<li><p>We then define the complexity, <em>i.e.</em>, $\Omega$. We define it by: the number of the leave nodes $T$, and the <strong>L2 Norm</strong> of the weight vectors of the leave nodes. Thus, we define $\Omega(f_t) &#x3D; \gamma T + \frac{1}{2}\lambda\sum_{j&#x3D;1}^T\omega_j^2$.</p>
</li>
<li><p>Merge the terms according to their order:<br> $$ {Loss}^{(t)} &#x3D; \sum_{j&#x3D;1}^T[(\sum_{i \in I_j}g_i)w_j + \frac{1}{2}(\sum_{i \in I_j}h_i + \lambda)w_j^2] + \gamma T$$<br> We can denote $G_j &#x3D; (\sum_{i \in I_j}g_i)$ and $H_j &#x3D; \sum_{i \in I_j}h_i$, these two stands for sum of the 1 &#x2F; 2 - order partial derivative of the samples contained by leave node $j$. Note that $G_j$, $H_j$ are constants.</p>
</li>
</ol>
<h3 id="Optimal-Solution"><a href="#Optimal-Solution" class="headerlink" title="Optimal Solution"></a>Optimal Solution</h3><p>We can tell that the objective function $f(w_j) &#x3D; G_jw_j + \frac{1}{2}(H_j + \lambda) w_j^2$ is a 2nd-order function about $w_j$. Thus, we can tell that the minial ($f(w_j) &#x3D; -\frac{G_j^2}{2(H_j + \lambda)}$) is reached at $w_j &#x3D; - \frac{G_j}{H_j + \lambda}$.</p>
<h1 id="LightGBM"><a href="#LightGBM" class="headerlink" title="LightGBM"></a>LightGBM</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><ol>
<li>Reduce the occupancy of memory. Utilize as much as possible data on single machine, without sacrificing the speed.</li>
<li>Reduce the overhead of communication, realize linear acceleration in case of Multiprocessor parallel.</li>
</ol>
<h2 id="Difference-from-XGBoost"><a href="#Difference-from-XGBoost" class="headerlink" title="Difference from XGBoost"></a>Difference from XGBoost</h2><ol>
<li>These two alogrithms both use the negative gradient of the loss function as the approximation of the residual of current decision tree, to fit the new decision tree.</li>
<li>LightGBM would grow in the vertical direction, and other algorithms would grow in the horizontal direction.</li>
<li>LightGBM would grow in the leave node with maximal error, to reduce loss as possible.</li>
</ol>
<h2 id="Histogram-Algorithm"><a href="#Histogram-Algorithm" class="headerlink" title="Histogram Algorithm"></a>Histogram Algorithm</h2><p><strong>Histogram Algorithm</strong> is proposed to substitute the <strong>pre-sorted algorithm</strong> of <strong>XGBoost</strong>. The pre-sorted algorithm would first sort the samples according to their feature values, then find the optimal split point from all the possible feature values. Thus, for each feature, the number of candidate split points is proportional to the <strong>number of samples</strong>.</p>
<p>At the same time, <strong>Histogram Algorithm</strong> would discretize the continuous feature values into a constant number (<em>e.g.</em>, 255) of bins. Thus, the candidate split points would reduce to <strong>(num_bins - 1)</strong> from <strong>(num_unique_values - 1)</strong>.</p>
<img src="/2022/05/25/DS-Study-Note-9/hist.png" class="" title="ML_note">

<p>With this manner, instead of storing the feature values with <code>float_32</code>, we can now use <code>uint_8</code> to store the index of bucket (with hash algorithm). At the same time, there comes the tradeoff of <strong>losing accuracy</strong> to <strong>raise efficiency</strong> </p>
<ul>
<li>(However, single Decision Tree itself is a weak model, it is not that important for the split points to be accurate. Coarse split points may have the <strong>regularization</strong> effect and the result can <strong>stay robust</strong> under Gradient Boosting framework.).<h3 id="Acceleration-of-Histogram-via-finding-difference"><a href="#Acceleration-of-Histogram-via-finding-difference" class="headerlink" title="Acceleration of Histogram via finding difference"></a>Acceleration of Histogram via finding difference</h3>The histogram of a leaf can be found by solving the difference of its father node’s histogram and its brother’s histogram. <strong>LightGBM</strong> can solve the histogram of a leaf node (with small sample number) and quickly find the histogram of its brother.<img src="/2022/05/25/DS-Study-Note-9/hist2.jpg" class="" title="ML_note"></li>
</ul>
<p>It should be noted that <strong>XGB</strong> and <strong>LightGBM</strong> only consider non-zero values.</p>
<h3 id="Leaf-wise-Algorithm-with-Depth-Limit"><a href="#Leaf-wise-Algorithm-with-Depth-Limit" class="headerlink" title="Leaf-wise Algorithm with Depth Limit"></a>Leaf-wise Algorithm with Depth Limit</h3><p>Most GBDT algorithms use the <strong>level-wise</strong> grow strategy, <em>i.e.</em>, all the leave nodes in the same level would be splitted, under a single traverse (then <strong>post-pruning</strong> would be executed). It is friendly for multi-thread optimization, controlling of model complexity and resist over-fitting. However, for many leaves, the <strong>split gain</strong> is very <strong>low</strong> and result in useless computational overhead. </p>
<p>LightGBM uses the <strong>leaf-wise</strong> grow strategy. At a time, a leaf with <strong>max split gain</strong> is selected and splitted. Thus, with the same number of splition, we can come up with better accuracy and lower error. However, it also has the advantage of possibility of <strong>overfitting</strong>, as a deep decision tree may be generated. Thus, a <code>max_depth</code> is introduced to control the depth of a tree.</p>
<h2 id="GOSS-Gradient-Based-One-Side-Sampling"><a href="#GOSS-Gradient-Based-One-Side-Sampling" class="headerlink" title="GOSS - Gradient Based One-Side Sampling"></a>GOSS - Gradient Based One-Side Sampling</h2><p><strong>GOSS</strong> aims at omitting most of the samples with <strong>small gradient</strong> and only use the remaining samples to compute the information gain. (We assume that the samples with smaller gradients are already <strong>well-trained</strong>.)</p>
<p>However, simply dropping the data with small gradient would change the overall distribution of dataset. Thus, <strong>GOSS</strong> would sort all the possible values of the feature to be splitted order by the absolute value and select the $k$-largest ones. Then, $m-k$ samples and randomly selected from the remaining ones (and assigned with a constant $fact$ to scale the samples with small gradient).</p>
<h2 id="EFB-Exclusive-Feature-Bundling"><a href="#EFB-Exclusive-Feature-Bundling" class="headerlink" title="EFB - Exclusive Feature Bundling"></a>EFB - Exclusive Feature Bundling</h2><p>High-dimensional data is usually <strong>sparse</strong>. Such sparsity inspires us to develop a <strong>lossless</strong> method to reduce the dimension of features. If two features are <strong>exclusive</strong>, it means that their feature would not be non-zero values at the same time. Then, we can simply find the sum of these two (<strong>Bundling</strong>), without losing information. If they are not completely exclusive, we can measure the <strong>conflict ratio</strong> (ratio of having non-zero values at the same time) of a pair of features. If <strong>conflict ratio</strong> is small, we can still bundle them without impair the final accuracy.</p>
<p><strong>Exclusive Feature Bundling, EFB</strong> points out that if we conduct fusion and bundling on some features, we can reduce the number of features for better performance.</p>
<h3 id="Decide-which-features-to-bundle"><a href="#Decide-which-features-to-bundle" class="headerlink" title="Decide which features to bundle"></a>Decide which features to bundle</h3><p>Bundling <strong>pair-wise independent</strong> features is a <strong>NP-Hard</strong> problem. The <strong>EFB</strong> algorithm of <strong>LightGBM</strong> reduces this problem into <strong>Graph Coloring Algorithm</strong>. Each feature would be viewed as a <strong>vertex</strong> of the graph, and we draw an <strong>edge</strong> between two features which are <strong>NOT completely independent</strong> and the <strong>weight</strong> of the edge is the <strong>conflict ratio</strong> of these two features. Then our task is to color the vertices to be bundled in the same color.</p>
<ul>
<li>The <strong>heuristic</strong> alogrithm is like: <strong>Construct</strong> such a graph, <strong>sort</strong> the vertices by the degree (larger degree means higher degree of conflict). <strong>Traverse</strong> each vertex (feature), allocate it to one of the existing feature bundles or create a new one, to minimize the total conflict.</li>
<li>When the scale of data is very large, the efficency of graph operation would get too low. <strong>LightGBM</strong> proposes a <strong>non-graph algorithm</strong>, which sort the features by the number of <strong>non-zero values</strong>.</li>
</ul>
<h3 id="Implement-the-bundling"><a href="#Implement-the-bundling" class="headerlink" title="Implement the bundling"></a>Implement the bundling</h3><p>We can distribute values of different features into <strong>different bins</strong> of a bundle (in order to make sure the values of raw features are <strong>recognizable before bundling</strong>, by adding a <strong>shifting constant</strong> to the feature value).</p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>It is not recommended to use LightGBM on small dataset as it is <strong>sensitive to overfitting</strong>. (Recommend to use LightGBM on dataset with a size larger than 10K)</p>
<h3 id="Categorical-Feature"><a href="#Categorical-Feature" class="headerlink" title="Categorical Feature"></a>Categorical Feature</h3><p>It should be noted that, <strong>one-hot encoding</strong> is not recommended for <strong>Decision Tree</strong> (especially when the number of classes is large).</p>
<ol>
<li>The split would be <strong>imbalanced</strong>, which results in <strong>very small splitting gain</strong>. Using one-hot encoding means that on each decision node, we can only use <strong>one vs rest</strong> splitting (<em>e.g.</em>, decide a sample is dog or not). It is almost equivalent to not splitting at all.</li>
<li>One-hot encoding would cut samples of the same class into many <strong>small subspaces &#x2F; groups</strong> (statistics on small space may be <strong>inaccurate</strong>). <strong>LightGBM</strong> use <strong>many-to-many</strong> to solve this issue (<em>e.g.</em>, a single node is $X &#x3D; A || X &#x3D; C$).</li>
</ol>
<p><strong>Acceleration method</strong>: Before traverse all the candidate splitting points, first sort the histogram by the mean value of the corresponding labels, then search the optimal splitting point according to the order. This method can easily <strong>overfitting</strong>, so it needs further <strong>constraints</strong> and <strong>regularization</strong>.</p>
<h3 id="Source-Code"><a href="#Source-Code" class="headerlink" title="Source Code"></a>Source Code</h3><p>When running in parallel, <strong>LightGBM</strong> would store all the training data in each node (server) to save the communication cost (instead of dividing the data vertically and distributing to each node). LightGBM would also use <strong>Reduce Scatter</strong> to distribute the task of merging the histogram. Finally, it applies parallizing based on <strong>voting</strong> (only the <strong>Top K</strong> features of <strong>each node</strong> would be considered and merged). Also, the histogram algorithm <strong>LightGBM</strong> applied is naturally more friendly to <strong>Cache</strong>, because it reduce the <strong>random access</strong> and do not need a data structure to store the mapping of <strong>row indexes to leave indexes</strong>.</p>
<p>Recommended web for source code studying: <a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/XxFHmxV4_iDq8ksFuZM02w">https://mp.weixin.qq.com/s/XxFHmxV4_iDq8ksFuZM02w</a></p>
<h1 id="Summary-on-Bagging-and-Boosting"><a href="#Summary-on-Bagging-and-Boosting" class="headerlink" title="Summary on Bagging and Boosting"></a>Summary on Bagging and Boosting</h1><ol>
<li><p><strong>Sample Selection</strong>:<br> <strong>Bagging</strong>: sampling with replacement, different training sets are independent from each other<br> <strong>Boosting</strong>: The training set remains unchanged, only the weight of each sample alters (decided by the performance of last round).</p>
</li>
<li><p><strong>Weight of sample</strong>:<br> <strong>Bagging</strong>: Each sample has the same weight.<br> <strong>Boosting</strong>: Weight decided by the error rate (higher error rate corresponds to higher weight).</p>
</li>
<li><p><strong>Weight of learner</strong>:<br> <strong>Bagging</strong>: Each learner has the same weight.<br> <strong>Boosting</strong>: Each weak learner has different weight (more accurate one has higher weight).</p>
</li>
<li><p><strong>Parallel computing</strong>:<br> <strong>Bagging</strong>: Able to parallel.<br> <strong>Boosting</strong>: Each learner should be generated in sequential order.</p>
</li>
<li><p><strong>Essence</strong>:<br> <strong>Bagging</strong>: Reduce variance (via voting).<br> <strong>Boosting</strong>: Reduce bias.</p>
</li>
</ol>

        </div>
        <footer class="article-footer">
            



    <a data-url="https://umiao.github.io/2022/05/25/DS-Study-Note-9/" data-id="clb62ia2f000grktj36o31yaa" class="article-share-link"><i class="fa fa-share"></i>Share</a>
<script>
    (function ($) {
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

        </footer>
    </div>
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "author": {
            "@type": "Person",
            "name": "Blur - Shenghui Xu"
        },
        "headline": "DS-Study-Note-9 Gradient Boosting Machine Tree Model(s)",
        "image": "https://umiao.github.io/2022/05/25/DS-Study-Note-9/theory.jpg",
        "keywords": "DataScience Machine Learning GBM XGBoost",
        "genre": "Data Science General Knowledge",
        "datePublished": "2022-05-25",
        "dateCreated": "2022-05-25",
        "dateModified": "2022-05-28",
        "url": "https://umiao.github.io/2022/05/25/DS-Study-Note-9/",
        "description": "Gradient Boosting Machine TreeGBMTree stands for Gradient Boosting Machine Tree.",
        "wordCount": 2421
    }
</script>

</article>

    <section id="comments">
    
        
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>


    
    </section>



                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>follow:</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="twitter" href="/" target="_blank" rel="noopener">
                        <i class="icon fa fa-twitter"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="facebook" href="https://www.facebook.com/profile.php?id=100073921278130" target="_blank" rel="noopener">
                        <i class="icon fa fa-facebook"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="stack-overflow" href="/" target="_blank" rel="noopener">
                        <i class="icon fa fa-stack-overflow"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/umiao" target="_blank" rel="noopener">
                        <i class="icon fa fa-github"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="weibo" href="/" target="_blank" rel="noopener">
                        <i class="icon fa fa-weibo"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="rss" href="/" target="_blank" rel="noopener">
                        <i class="icon fa fa-rss"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2022/06/20/NLP-1/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption">newer</strong>
        <p class="article-nav-title">
        
            NLP-1 Roadmap
        
        </p>
        <i class="icon fa fa-chevron-right" id="icon-chevron-right"></i>
    </a>
    
    
        <a href="/2022/05/14/SQL-Study-Note-16/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">older</strong>
        <p class="article-nav-title">SQL-Study-Note-16 Optimization Discussion 3 - Optimize the condition setting and table creating</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                

            
                
    <div class="widget-wrap">
        <h3 class="widget-title">recents</h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2023/09/17/Name-of-Every-Keyboard-s-Key/" class="thumbnail">
    
    
        <span style="background-image:url(/2023/09/17/Name-of-Every-Keyboard-s-Key/cover.jpg)" alt="Name of Every Keyboard&#39;s Key" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Job-Search/">Job Search</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/Job-Search/Software-Engineering/">Software Engineering</a></p>
                            <p class="item-title"><a href="/2023/09/17/Name-of-Every-Keyboard-s-Key/" class="title">Name of Every Keyboard&#39;s Key</a></p>
                            <p class="item-date"><time datetime="2023-09-18T05:52:17.000Z" itemprop="datePublished">2023-09-17</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2023/09/17/Basics-About-Linux-Vim-Usage/" class="thumbnail">
    
    
        <span style="background-image:url(/2023/09/17/Basics-About-Linux-Vim-Usage/cover.jpg)" alt="Basics About Linux &amp; Vim Usage" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Job-Search/">Job Search</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/Job-Search/Software-Engineering/">Software Engineering</a></p>
                            <p class="item-title"><a href="/2023/09/17/Basics-About-Linux-Vim-Usage/" class="title">Basics About Linux &amp; Vim Usage</a></p>
                            <p class="item-date"><time datetime="2023-09-18T05:16:13.000Z" itemprop="datePublished">2023-09-17</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2023/09/15/Learn-English-Vocabulary-by-Frequency/" class="thumbnail">
    
    
        <span style="background-image:url(/2023/09/15/Learn-English-Vocabulary-by-Frequency/cover.jpg)" alt="Learn English Vocabulary by Frequency" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Productivity/">Productivity</a></p>
                            <p class="item-title"><a href="/2023/09/15/Learn-English-Vocabulary-by-Frequency/" class="title">Learn English Vocabulary by Frequency</a></p>
                            <p class="item-date"><time datetime="2023-09-16T06:01:32.000Z" itemprop="datePublished">2023-09-15</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2023/09/10/Options-Futures-and-Other-Derivatives-Note-2/" class="thumbnail">
    
    
        <span style="background-image:url(/2023/09/10/Options-Futures-and-Other-Derivatives-Note-2/cover.jpg)" alt="Options Futures and Other Derivatives - Note - 2" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Investment/">Investment</a></p>
                            <p class="item-title"><a href="/2023/09/10/Options-Futures-and-Other-Derivatives-Note-2/" class="title">Options Futures and Other Derivatives - Note - 2</a></p>
                            <p class="item-date"><time datetime="2023-09-11T06:59:30.000Z" itemprop="datePublished">2023-09-10</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2023/09/09/Options-Futures-and-Other-Derivatives-Note-1/" class="thumbnail">
    
    
        <span style="background-image:url(/2023/09/09/Options-Futures-and-Other-Derivatives-Note-1/cover.jpg)" alt="Options Futures and Other Derivatives - Note - 1" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Investment/">Investment</a></p>
                            <p class="item-title"><a href="/2023/09/09/Options-Futures-and-Other-Derivatives-Note-1/" class="title">Options Futures and Other Derivatives - Note - 1</a></p>
                            <p class="item-date"><time datetime="2023-09-09T19:42:55.000Z" itemprop="datePublished">2023-09-09</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">categories</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/AI/">AI</a><span class="category-list-count">2</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/AI/NLP/">NLP</a><span class="category-list-count">2</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Science/">Data Science</a><span class="category-list-count">25</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Science/General-Knowledge/">General Knowledge</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Science/SQL/">SQL</a><span class="category-list-count">16</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Investment/">Investment</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Job-Search/">Job Search</a><span class="category-list-count">21</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Job-Search/Financial-Firm/">Financial Firm</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Job-Search/SQL/">SQL</a><span class="category-list-count">16</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Job-Search/Software-Engineering/">Software Engineering</a><span class="category-list-count">3</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Productivity/">Productivity</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/UCLA/">UCLA</a><span class="category-list-count">2</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/UCLA/Course-Study/">Course Study</a><span class="category-list-count">2</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/UCLA/Course-Study/ECE209-in-2022-spring/">ECE209 in 2022 spring</a><span class="category-list-count">2</span></li></ul></li></ul></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">archives</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/09/">September 2022</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/07/">July 2022</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/06/">June 2022</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/05/">May 2022</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/04/">April 2022</a><span class="archive-list-count">17</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">tags</h3>
        <div class="widget">
            <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Apple-Watch/" rel="tag">Apple Watch</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Brainteasers/" rel="tag">Brainteasers</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CLI/" rel="tag">CLI</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Certificate/" rel="tag">Certificate</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Cyber-Security/" rel="tag">Cyber Security</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DataScience/" rel="tag">DataScience</a><span class="tag-list-count">27</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/English/" rel="tag">English</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GBM/" rel="tag">GBM</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/IQ/" rel="tag">IQ</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Keyboard/" rel="tag">Keyboard</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/" rel="tag">Linux</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a><span class="tag-list-count">9</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Math/" rel="tag">Math</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/" rel="tag">NLP</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Naive-Bayes/" rel="tag">Naive Bayes</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/OOD/" rel="tag">OOD</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Object-Oriented-Design/" rel="tag">Object Oriented Design</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Productivity/" rel="tag">Productivity</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Random-Forest/" rel="tag">Random Forest</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Regularization/" rel="tag">Regularization</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SQL/" rel="tag">SQL</a><span class="tag-list-count">16</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SVM/" rel="tag">SVM</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Software-Engineering/" rel="tag">Software Engineering</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Term/" rel="tag">Term</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tips/" rel="tag">Tips</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/UCLA/" rel="tag">UCLA</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Vim/" rel="tag">Vim</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Vocabulary/" rel="tag">Vocabulary</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Word-Frequency/" rel="tag">Word Frequency</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/XGBoost/" rel="tag">XGBoost</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/futures/" rel="tag">futures</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/investment/" rel="tag">investment</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/options/" rel="tag">options</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/trading/" rel="tag">trading</a><span class="tag-list-count">2</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">tag cloud</h3>
        <div class="widget tagcloud">
            <a href="/tags/Apple-Watch/" style="font-size: 10px;">Apple Watch</a> <a href="/tags/Brainteasers/" style="font-size: 10px;">Brainteasers</a> <a href="/tags/CLI/" style="font-size: 10px;">CLI</a> <a href="/tags/Certificate/" style="font-size: 10px;">Certificate</a> <a href="/tags/Cyber-Security/" style="font-size: 10px;">Cyber Security</a> <a href="/tags/DataScience/" style="font-size: 20px;">DataScience</a> <a href="/tags/English/" style="font-size: 10px;">English</a> <a href="/tags/GBM/" style="font-size: 10px;">GBM</a> <a href="/tags/IQ/" style="font-size: 10px;">IQ</a> <a href="/tags/Keyboard/" style="font-size: 10px;">Keyboard</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/Machine-Learning/" style="font-size: 15px;">Machine Learning</a> <a href="/tags/Math/" style="font-size: 10px;">Math</a> <a href="/tags/NLP/" style="font-size: 12.5px;">NLP</a> <a href="/tags/Naive-Bayes/" style="font-size: 10px;">Naive Bayes</a> <a href="/tags/OOD/" style="font-size: 10px;">OOD</a> <a href="/tags/Object-Oriented-Design/" style="font-size: 10px;">Object Oriented Design</a> <a href="/tags/Productivity/" style="font-size: 10px;">Productivity</a> <a href="/tags/Random-Forest/" style="font-size: 10px;">Random Forest</a> <a href="/tags/Regularization/" style="font-size: 10px;">Regularization</a> <a href="/tags/SQL/" style="font-size: 17.5px;">SQL</a> <a href="/tags/SVM/" style="font-size: 10px;">SVM</a> <a href="/tags/Software-Engineering/" style="font-size: 12.5px;">Software Engineering</a> <a href="/tags/Term/" style="font-size: 10px;">Term</a> <a href="/tags/Tips/" style="font-size: 10px;">Tips</a> <a href="/tags/UCLA/" style="font-size: 12.5px;">UCLA</a> <a href="/tags/Vim/" style="font-size: 10px;">Vim</a> <a href="/tags/Vocabulary/" style="font-size: 10px;">Vocabulary</a> <a href="/tags/Word-Frequency/" style="font-size: 10px;">Word Frequency</a> <a href="/tags/XGBoost/" style="font-size: 10px;">XGBoost</a> <a href="/tags/futures/" style="font-size: 12.5px;">futures</a> <a href="/tags/investment/" style="font-size: 12.5px;">investment</a> <a href="/tags/options/" style="font-size: 12.5px;">options</a> <a href="/tags/trading/" style="font-size: 12.5px;">trading</a>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">links</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a target="_blank" rel="noopener" href="http://hexo.io">Hexo</a>
                    </li>
                
            </ul>
        </div>
    </div>


            
        
    </div>
</aside>

                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
<!--             <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" class="logo"></a>
                </h1>
                <p>&copy; 2023 Blur - Shenghui Xu</p>
                
                <p>Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="https://github.com/ppoffice" target="_blank">PPOffice</a></p>
                
            </div> -->
            <div class="footer-plugins">
              
    


            </div>
        </div>
    </div>
</footer>


  <script src='https://unpkg.com/mermaid@8.11.0/dist/mermaid.min.js'></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({theme: 'forest'});
    }
  </script>

    </div>
    
    
    <script>
    var disqus_shortname = 'hexo-theme-hueman';
    
    
    var disqus_url = 'https://umiao.github.io/2022/05/25/DS-Study-Note-9/';
    
    (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>





    
        
<script src="/libs/lightgallery/js/lightgallery.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-pager.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-zoom.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-hash.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-share.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-video.min.js"></script>

    
    
        
<script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>

    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML.js"></script>

    

    
    
    




<!-- Custom Scripts -->

<script src="/js/main.js"></script>


</body>
</html>
