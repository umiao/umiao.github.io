{"meta":{"title":"The blog of Blur","subtitle":"Hearing the fall of snow.","description":"Personal blog of blur.","author":"Blur - Shenghui Xu","url":"https://umiao.github.io","root":"/"},"pages":[{"title":"About Me","date":"2022-04-16T17:45:16.000Z","updated":"2022-04-21T18:32:14.752Z","comments":true,"path":"about/index.html","permalink":"https://umiao.github.io/about/index.html","excerpt":"","text":"Who am i This is Shenghui Xu and welcome to my blog. I am currently a year-one MS student with the Electrical Computer Engineering department of University of California, Los Angeles. I am now focusing on the track of Signals &amp; Systems and have a GPA of 4.0. I am also an incoming applied researcher intern at ebay. Before I went to UCLA, I was an undergraduate student majored in Computer Science with Soochow University. I graduated with honor in Jun. 2020 (with a GPA of 3.83). Skills and Tools Languages Python &#x2F; Matlab &#x2F; R &#x2F; Java &#x2F; JavaScript &#x2F; C++ Bash &#x2F; CMD &#x2F; Code Climate Frameworks TensorFlow &#x2F; Torch &#x2F; Keras &#x2F; Theano &#x2F; CUDA &#x2F; CUDNN Scikit-learn &#x2F; nltk &#x2F; Numpy &#x2F; Spark (PySpark) Qt Web HTML&#x2F;HTML5 &#x2F; CSS &#x2F; Node.js jQuery &#x2F; Vue.js &#x2F; quasar Tornado &#x2F; Chrome Dev Tools Editor &amp; IDE VIM &#x2F; Sublime Text &#x2F; Notepad++ &#x2F; Lime Text Visual Studio &#x2F; Qtcreator &#x2F; Pycharm &#x2F; Eclipse Version Control &amp; Deployment Git &#x2F; SVN &#x2F; Github &#x2F; GitLab &#x2F; Gitee &#x2F; Anaconda &#x2F; npm Testing Jenkins &#x2F; Lint &#x2F; Pytest &#x2F; Docker &#x2F; Unit Testing Data Management MySQL &#x2F; MongoDB &#x2F; Redis &#x2F; Memcached Projects Experiences"}],"posts":[{"title":"DS-Study-Note-3 Dimension Curse","slug":"DS-Study-Note-3","date":"2022-04-26T22:19:27.000Z","updated":"2022-04-26T22:24:49.700Z","comments":true,"path":"2022/04/26/DS-Study-Note-3/","link":"","permalink":"https://umiao.github.io/2022/04/26/DS-Study-Note-3/","excerpt":"","text":"DefinitionDimension curse stands for the troubles you would meet when processing high-dimensional data.","categories":[{"name":"Data Science","slug":"Data-Science","permalink":"https://umiao.github.io/categories/Data-Science/"},{"name":"General Knowledge","slug":"Data-Science/General-Knowledge","permalink":"https://umiao.github.io/categories/Data-Science/General-Knowledge/"}],"tags":[{"name":"DataScience","slug":"DataScience","permalink":"https://umiao.github.io/tags/DataScience/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://umiao.github.io/tags/Machine-Learning/"}]},{"title":"DS-Study-Note-2 Bias VS Variance","slug":"DS-Study-Note-2","date":"2022-04-23T07:41:01.000Z","updated":"2022-04-26T22:18:22.843Z","comments":true,"path":"2022/04/23/DS-Study-Note-2/","link":"","permalink":"https://umiao.github.io/2022/04/23/DS-Study-Note-2/","excerpt":"The target of Machine Learning is to fit an (unknown) distribution. There lies three possible error: bias, variance and irreducible error.","text":"The target of Machine Learning is to fit an (unknown) distribution. There lies three possible error: bias, variance and irreducible error. The irreducible error CANNOT be avoided with any algorithm as it can be viewed as the result of unknown factor, noise, accidents, etc. Thus, we would focus on the bias and variance error. Definition Bias can be understood as the accuracy of the model, i.e., the ability to estimate the output value accurately. Variance can be understood as the stability of the model, i.e., the ability of resisting the noise and disturbance contained by the input. I also understood this ability as being able to recognize similar inputs and generate similar results for them. Example Applying K-fold cross validation can reduce the influence casted by the outliers and enhance the generalization ability, which reduces the variance error. At the same time, part of the data is not used for training, which impairs the model’s fitting ability and increase the bias error. An intuition is that, a more complex model is more sensitive to the noise contained by the input, which makes the output less stable (higher variance error). At the same time, a simpler model more easily ignores the random noise and difference of distribution between the training set and the testing set. Tradeoff and AnalysisThe variance of the parameters you are estimating can be reduced, at the cost of increasing bias. If you would like to generalize a model trained on a certain training set, then you CANNOT minimize the bias and variance error at the same time. Bias: Bias error comes from the erroneous assumptions of the learning algorithm. High bias error corresponds to underfitting. Bias error measures the closeness between the distribution you modeled and the expectation of the real distribution. Introduction of bias term in linear models aims at simplying the learning process without introducing way more complicated distribution which makes the model hard to generalize. At the same time, such models would fail to solve the more complicated models which do not meet the assumption (that this problem can be approximated by linear model). Variance: Variance error comes from the noise &#x2F; fluctuation &#x2F; disturbance of the training set. High variance error probably means that you are modeling on the random noise of the training set, which cannot be generalized, and this means overfitting. Variance error reveals the level of concentration of your model.","categories":[{"name":"Data Science","slug":"Data-Science","permalink":"https://umiao.github.io/categories/Data-Science/"},{"name":"General Knowledge","slug":"Data-Science/General-Knowledge","permalink":"https://umiao.github.io/categories/Data-Science/General-Knowledge/"}],"tags":[{"name":"DataScience","slug":"DataScience","permalink":"https://umiao.github.io/tags/DataScience/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://umiao.github.io/tags/Machine-Learning/"}]},{"title":"DS-Study-Note-1 Overfitting and Brief Introduction on Decomposition and Regularization","slug":"DS-Study-Note-1","date":"2022-04-22T16:23:14.000Z","updated":"2022-04-23T07:37:49.936Z","comments":true,"path":"2022/04/22/DS-Study-Note-1/","link":"","permalink":"https://umiao.github.io/2022/04/22/DS-Study-Note-1/","excerpt":"Overfitting is a modeling error in statistics that occurs when a function is too closely aligned to a limited set of data points. —- Definition ranked 1st in Google","text":"Overfitting is a modeling error in statistics that occurs when a function is too closely aligned to a limited set of data points. —- Definition ranked 1st in Google Definition Overfitting stands for making excessive learning steps on the training set, which results in the model extracting noise of the training set as valid pattern to fit the training set’s distribution. In this case, the trained model would show low performance on the testing set and new data (real-world data). Possible Causes: The volume of the training data is too small. The data distribution of the training set data does NOT subject to the testing and real business data. This also means that the iid (identically and independent distributed) assumption is not satisfied. There exists noise in the training set. Too many iteration times. Fail to learn correct features with ability of generalization and representative. The overfitting MAY be phenomenon of information leakage, i.e., too complicated model remembers the training which makes the inference equivalent to the table look-up. Solutions: Discard some features. This can be implemented by Feature Selection or simply randomly discard a subset. This process can be: Conducted manually. Randomly. (Random Forest) Decided by Model Selection Algorithm. E.g., PCA(Principal component analysis). PCA: Solve the eigen-vector of the covariance matrix. It is obvious that the larger the covariance is, the more useful the corresponding eigen-value is. Find the largest k eigen-values and use their corresponding eigen-vectors to form a matrix as the PCA output. (You can also use SVD for such decomposition.) You can also use dimensional reduction tools like LR(lower–upper) decomposition, SVD(Singular Value Decomposition). Introduce regularization. Introduce drop-out layer when training network. Use Early-Stop to achieve the tradeoff the generalization ability and convergence on the training set. (In this case, evaluation set is required for observation.) A combination of methods above. Adopt models like Random Forest. Any method which is believed to be able to control the model’s complexity. E.g., control the depth, number of trees. Selection Bewteen the L1 and L2 Regularization Term L1 - LASSO (Least Absolute Shrinkage and Selection Operator): cast penalty on the sum of the absolute value of the model parameters.Regularize all the parameters equally. Able to transform some parameters into 0. (make the model sparse)$${L1}_{reg} &#x3D; \\lambda \\sum_{j&#x3D;1}^p |\\beta _j|$$ L2 - Ridge Regression: cast penalty on the sum of the square value of the model parameters.$${L2}_{reg} &#x3D; \\lambda \\sum_{j&#x3D;1}^p \\beta _j^2$$ In essence, these two regularization method is to conduct L1 &#x2F; L2 Normalization on the model parameters and add the normalized term to the Loss Function for optimization.","categories":[{"name":"Data Science","slug":"Data-Science","permalink":"https://umiao.github.io/categories/Data-Science/"},{"name":"General Knowledge","slug":"Data-Science/General-Knowledge","permalink":"https://umiao.github.io/categories/Data-Science/General-Knowledge/"}],"tags":[{"name":"DataScience","slug":"DataScience","permalink":"https://umiao.github.io/tags/DataScience/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://umiao.github.io/tags/Machine-Learning/"}]},{"title":"SQL-Study-Note-11 User and Privilege Management","slug":"SQL-Study-Note-11","date":"2022-04-21T19:39:39.000Z","updated":"2022-04-21T22:06:33.950Z","comments":true,"path":"2022/04/21/SQL-Study-Note-11/","link":"","permalink":"https://umiao.github.io/2022/04/21/SQL-Study-Note-11/","excerpt":"Most data science practitioners would not be granted the privilege of managing the database system (not even the privilege to update &#x2F; delete), so…","text":"Most data science practitioners would not be granted the privilege of managing the database system (not even the privilege to update &#x2F; delete), so… Create and Manage User1234567891011121314CREATE USER join@&#x27;%.google.com&#x27; IDENTIFIED BY &#x27;1234&#x27;;-- You can restrict the domain of user with this method.-- You can also specify an ip after &#x27;@&#x27;.-- &#x27;1234&#x27; Stands for the password.SELECT * FROM mysql.USER;-- Retrieve the information of all the users.-- It is also supported to use GUI interface to manage the user,\\-- their host to log in with, etcDROP USER bob@gmail.com;-- Drop a user.SET PASSWORD (john) = &#x27;1234&#x27;;-- Reset a user&#x27;s password.-- It is also supported to EXPIRE PASSWORD for one user.-- So that he would be required to change the password by next log in. Privilege Management12345678GRANT SELECT, INSERT, UPDATE, DELETE, EXECUTE ON sql_store.* TO user_a;-- An example of granting the privileges.SHOW GRANTS;-- Show all the grantsREVOKE privilege .. ;-- Revoke specified granted privilege. Refer documentation for more related instructions.","categories":[{"name":"Data Science","slug":"Data-Science","permalink":"https://umiao.github.io/categories/Data-Science/"},{"name":"SQL","slug":"Data-Science/SQL","permalink":"https://umiao.github.io/categories/Data-Science/SQL/"},{"name":"Job Search","slug":"Job-Search","permalink":"https://umiao.github.io/categories/Job-Search/"},{"name":"SQL","slug":"Job-Search/SQL","permalink":"https://umiao.github.io/categories/Job-Search/SQL/"}],"tags":[{"name":"DataScience","slug":"DataScience","permalink":"https://umiao.github.io/tags/DataScience/"},{"name":"SQL","slug":"SQL","permalink":"https://umiao.github.io/tags/SQL/"}]},{"title":"SQL-Study-Note-10 Index","slug":"SQL-Study-Note-10","date":"2022-04-21T17:53:59.000Z","updated":"2022-04-21T19:55:39.737Z","comments":true,"path":"2022/04/21/SQL-Study-Note-10/","link":"","permalink":"https://umiao.github.io/2022/04/21/SQL-Study-Note-10/","excerpt":"Index can be used to find the row (line) numbers corresponding to the value being queried. Index is added to certain columns and is stored in memory (RAM) for most times.","text":"Index can be used to find the row (line) numbers corresponding to the value being queried. Index is added to certain columns and is stored in memory (RAM) for most times. Create IndexIndex can speed up the query, however, it would also increase the size (memory comsuption) of database as well as the cost of maintenance. It is usually implemented by binary tree in database systems. 12CREATE INDEX idx_state ON customers (state);-- Specify a column of a table to create an index. Explain and ANALYZE1EXPLAIN SELECT * FROM ... Add EXPLAIN before a sql query would get explanatory information instead of the query result. E.g., which information is used and how many records are went through, for performance evaluation. 123456SHOW INDEXES IN customers;-- Reveal all the indexes in the customers table.-- You can find out the indexes added, the cardinality and name.ANALYZE TABLE customers;-- Indexes includes primary index, secondary index, etc.-- You can use the ANALYZE command to view the statistics and values of a table Different Index Types prefix indexYou should create prefix index, instead of index on the entire column, for acceleration.12345CREATE INDEX idx_n ON customers (last_name(20));-- In this case, the last_name column would be grouped and indexed according to the first 20 characters only.COUNT (DISTINCT LEFT(last_name, 10));-- You can use this way to analyze the performance of creating prefix index on the first 10 characters. -- If the number of distinct values is large enough, then this prefix is able to differentiate the possible values. Full-Text IndexThe idea of such index is similar to the implementation principles of Search Engines. For all the non-stop words, record the corresponding passages (rows) and the position where they appear.1234567CREATE FULLTEXT INDEX idex_t_body ON posts (title, body);-- FULLTEXT INDEX can monitor multiple columns.SELECT * FROM posts WHERE MATCH(title, body) AGAINST (&#x27;react redux&#x27;);-- Search &#x27;react redux&#x27; in the two columns: title and body. They are viewed as TWO words.MATCH(title, body) AGAINST (&#x27;react -redux +form&#x27; IN BOOLEAN MODE);-- It is possible to exclude some words by adding a &#x27;-&#x27;.-- So the above query matches contents including react/form and without redux. Composite indexesEnable indexing on multiple columns in order to solve the issue that too many results are returned after filtering with the primary index. You can use the appearing order of the columns to decide the filtering priority of the Composite indexes.1CREATE INDEX idx_n ON customers (last_name, state, points); MySQL supports Composite index to include at most 16 columns. However, including 4-6 columns is fairly enough in practice. At the same time, Composite index supports sorting on the columns so that the more frequently used columns appear ahead. In fact, you can decide the priority of the indexes being used, by changing the appearing order of the conditions of the WHERE clause. You can use the command of: 1USE INDEX idx_name; to force MySQL to use certain index, even it is not optimal. You can NOT make full use of the index, if column is included in the sql expression (e.g. in WHERE condtion). So extract the required column first before conducting transformation. Sorting and PerformanceSorting should be avoided as possibleIt is because it is costy. You should utilize Indexes for the purpose of sorting, as possible. 1234SHOW STATUS;-- Show the variables being used in MySQL server.last_query_cost;-- You can measure the cost of last query by this mean. It should be noted that, for column a and b, ORDER BY clause can use the Index for sorting if the order is among one of these: ORDER BY a ORDER BY b ORDER BY a, b ORDER BY a DESC, b DESCAny other order would introduce external sorting operation (which means Scaning the Entire Table!).There is an exception that if WHERE clause can locate to a Single Column, then external sorting would not happen. If you can achieve the result of query solely rely on the index, then it is a Overlay Index. Duplicate index and Redundant Index Duplicate Indexes: Repeatly create the same index, e.g. on columns (a, b, c). Redundant Indexes: One index’s functionality is completely covered by the other. E.g., creating index for column (a) and (a, b) at the same time. (The latter can cover the prior)","categories":[{"name":"Data Science","slug":"Data-Science","permalink":"https://umiao.github.io/categories/Data-Science/"},{"name":"SQL","slug":"Data-Science/SQL","permalink":"https://umiao.github.io/categories/Data-Science/SQL/"},{"name":"Job Search","slug":"Job-Search","permalink":"https://umiao.github.io/categories/Job-Search/"},{"name":"SQL","slug":"Job-Search/SQL","permalink":"https://umiao.github.io/categories/Job-Search/SQL/"}],"tags":[{"name":"DataScience","slug":"DataScience","permalink":"https://umiao.github.io/tags/DataScience/"},{"name":"SQL","slug":"SQL","permalink":"https://umiao.github.io/tags/SQL/"}]},{"title":"SQL-Study-Note-9 Data Modeling, Constraint and Normalization Form","slug":"SQL-Study-Note-9","date":"2022-04-20T22:22:22.000Z","updated":"2022-04-21T17:53:30.704Z","comments":true,"path":"2022/04/20/SQL-Study-Note-9/","link":"","permalink":"https://umiao.github.io/2022/04/20/SQL-Study-Note-9/","excerpt":"Data Modelling Pipeline Understand the requirements; Build a conceptual Model; Build a logical model; Build a physical model.","text":"Data Modelling Pipeline Understand the requirements; Build a conceptual Model; Build a logical model; Build a physical model. Foreign Key ConstraintAlthough modify the primary key IS NOT recommended, we would consider the update to the foreign key caused by the primary key anyway. Option (strategy of updating): restrict: restrict modification cascade: update the foreign keys according to the primary key set null: set the corresponding foreign key in the foreign table into NULL no action: reject the update It is highly not recommended to use set null, as it would result in organ record in the corresponding tables (no idea which id it belongs to). Dataset NormalizationNF-1 (First Normal Form):Each record unit (element specified by row and column index) should contain a single value only and contain NO duplicate column.E.g., if you want to add tags to the Course table, you should extract tags into an independent table (and use id mapping to retrieve the tags) for it to be extendable. NF-2 (Second Normal Form):Frist is to satisfy NF-1. Also, every non candidate-key attribute depends on the whole candidate keys (that is to say, they must not depend on a true subset of the candidate keys). That is to say, each table should contain exactly one entity category only. E.g., a table stores course information should NOT contain information like the enroll time of each student. If there is an attribute which does not belong to the entity represented by this table, create a new table to store it. NF-3 (Third Normal Form):Frist is to satisfy NF-2.Also, all the attributes of the table should be determined by candidate key (for example, id) and should NOT be determined by the other non-primary attributes.That is to say, all the columns of the table should NOT be generated &#x2F; derived by the other columns, to avoid errors caused by duplicate storage and erroneous update. Data Model $ \\leftrightarrow$ TableIn MySQL, you can use forward engineer to convert data model into actual tables. Its essence is to generate sql script for database &#x2F; table generation, with the specified data model &#x2F; structual graph.The script would be like: 123CREATE schema IF NOT EXISTS … USE schema … CREATE TABLE … It is also supported to regenerate and fix the table via modifying the data model. In this case, you should select synchronize model instead of forward engineer. For those table with foreign keys, if you want to update the table, foreign keys would prevent you from doing so (as a constraint). You should first drop all the foreign keys and then reconstruct it to link to correlated tables. Reverse EngineerIt is also supported to generate data model (graphs) from existing tables. That is reverse engineering.It is highly recommended that you only put ONE database into a single data model, unless these databases are really highly correlated. Data Management Opertion (Via SQL Script)Create of Database: 12CREATE DATABASE IF NOT EXISTS name;-- Make well use of EXISTS clause to avoid error. Create Table:1234567CREATE TABLE cus ( c_id, INT PRIMARY KEY AUTO_INCREMENT, first_name VARCHAR(50) NOT NULL, points INT NOT NULL DEFAULT 0, email VARCHAR(250) NOT NULL UNIQUE ) Use Alter Table to update Table:1234567ALTER TABLE customers ADD last_name VARCHAR(50) NOT NULL AFTER first_name-- You can also use MODIFY / DROP instead of ADD to edit and delete the existing and known columns. Add Constraints (e.g., Foreign Key):12345FOREIGN KEY fk_col_name (c_id 表中列名) REFERENCES customers(c_id) ON UPDATE NO ACTION ON DELETE NO ACTION -- You cannot drop a table without droping its foreign key constraints in advance. Charset1234567SHOW CHARSET; -- You can use this command to show the charset.CREATE / ALTER DATABASE db_name CHARACTER SET lain1;-- About modifying / altering the charset (for a dataset).CREATE / ALTER TABLE () CHARACTER SET latin1;-- You can set the charset in the table level, too.-- Also, charset can be set in column level, just like adding constriants like &#x27;NOT NULL&#x27; Database Engine &#x2F; Storage Engine1234SHOW ENGINES; -- Show all the engines.ALTER TABLE customers ENGINE = InnoDB;-- Specify the engine for a table.","categories":[{"name":"Data Science","slug":"Data-Science","permalink":"https://umiao.github.io/categories/Data-Science/"},{"name":"SQL","slug":"Data-Science/SQL","permalink":"https://umiao.github.io/categories/Data-Science/SQL/"},{"name":"Job Search","slug":"Job-Search","permalink":"https://umiao.github.io/categories/Job-Search/"},{"name":"SQL","slug":"Job-Search/SQL","permalink":"https://umiao.github.io/categories/Job-Search/SQL/"}],"tags":[{"name":"DataScience","slug":"DataScience","permalink":"https://umiao.github.io/tags/DataScience/"},{"name":"SQL","slug":"SQL","permalink":"https://umiao.github.io/tags/SQL/"}]},{"title":"Missing Value Imputation in Traffic Data","slug":"Missing-Value-Imputation-in-Traffic-Data","date":"2022-04-19T21:52:23.000Z","updated":"2022-04-20T21:22:37.055Z","comments":true,"path":"2022/04/19/Missing-Value-Imputation-in-Traffic-Data/","link":"","permalink":"https://umiao.github.io/2022/04/19/Missing-Value-Imputation-in-Traffic-Data/","excerpt":"Lost of sensor-generated data can be very common. The methods of imputation can be coarsely categorized into: 1. Prediction methods; 2. Interpolation methods; 3. Statistical Learning methods.","text":"Lost of sensor-generated data can be very common. The methods of imputation can be coarsely categorized into: 1. Prediction methods; 2. Interpolation methods; 3. Statistical Learning methods. Imputation problem &amp; Model FormulationLet $Y_c$ be the traffic dataset persists for $N$ consecutive days,$$ Y_c &#x3D; [Y(1), …, Y(N)] $$in which the ith $Y(i)$ be noted as 1-D vector$$ Y(i) &#x3D; [y_i(1), …, y_i(D)]^T, i \\in [1, N] $$.Concatenate all the vectors we have together, we would have:$$ Y_{series} &#x3D; [y(1), …, y(D \\times N)]^T $$. Typical traffic data includes the speed and number of vehicles on a certain lane at a time. These data can form a numerical time sequence. Such data can be collected by sensor installed on the roads or along the roadsides. ARIMA-based methodARIMA stands for Autoregressive Integrated Moving Average. In ARIMA(p, d, q), p denotes the order of the autoregressive part, d is the degree of differencing and q is the order of moving average part: $$ (1 - \\sum_{i&#x3D;1}^p \\alpha_i L^i) (1 - L)^d y(t) &#x3D; (1 + \\sum_{i&#x3D;1}^q \\beta_i L^i) y(t) \\xi(t) $$ and L is the backshift operator, $L_y(t) &#x3D; y(t- 1)$. $\\xi(t)$ is white Gaussian noise. First train this model with the known series and impute missing data one by one. The imputed data would be used as known data for next prediction. We use Akaike information criterion to determine $p$ and $q$. $d$ is suggested to be set to $1$. BNs-based imputation methodBN stands for Bayesian Netowrk. Based on the known dataset, learn the distribution model of multivariable variants $Y_{mv}(t) &#x3D; [y(t-m), …, y(t)]^T$.Assume this learning target as Gaussian mixture model (GMM).Use split and merge expectation maximisation algorithm to determine the model parameters. With a learnt GMM, missing data of $y(t)$ can be estimated as the expectation foregoing value from the latest $m$ items, as: $$ \\hat y(t) &#x3D; E[y(t) | y(t-m), …, y(t-1)] $$ k-NN based imputation methodWeighted k-NN is a non-parametric estimation method. Selection S-step (Selection Step):Use a metric to find $k$ nearest traffic daily flow vectors to the corrupted vector $Y(i)$ in pattern-similar from the dataset $Y_c$.Metrics can be Euclidean distance and Pearson correlation, for examples. Then, the lost entry &#x2F; dimension of $Y(i)$ can be imputed with the mean value of the (entries of the) $k$ vectors. Imputation I-step: (Imputation Step)Because our k-NN algorithm is weighted, then we need to find the weighted average of the k entries (averaged by the correlation coefficent given by the selected metric). Grid search and other optimization methods may be applied to determine best $k$. LLS-based imputation methodSelection S-step (Selection Step):Exactly the same as the above k-NN method. Imputation I-step: (Imputation Step)Decompose k selected vectors dataset into matrix $A$ and $B$. The dimension should be corresponding to the missing part of $Y_{mis}(i)$ and observed part $Y_{obs}(i)$ of $Y(i)$. We would have $$ \\hat Y_{mis}(i) &#x3D; B((A^TA)^{-1}A^T Y_{obs}(i)) $$. This is just a pseudo-inverse, $A$ should be full-ranked&#x2F; MCMC-based imputation methodFirst assume the entire data sequence $Y$ follows a certain distribution, e.g., Gaussian distribution.The conditional expectation $E[Y_{mis}|Y_{obs}, \\Phi]$ would be approximated by MCMC(Markov chain Monte Carlo) with DA(Data Augmentation), since the expectation is hard to be solved precisely due to its high dimension. Here $\\Phi$ stands for the parameter of the selected distribution. The MCMC with DA is a special case of Gibbs sampler described as follows: Imputation I-step: (Imputation Step)Given a current estimated model parameter $\\Phi ^k$, this step uses the conditional probability $Y_{mis}^{k+1}&#x3D;p(Y_{mis}|Y_{obs}, \\Phi)$ to simulate missing values for each observation independently. Posterior P-step:Use $p(\\Phi | Y_{obs}, Y_{mis}^{k+1})$ to update model parameter $\\Phi$. In this manner, a Markov chain of $(Y_{mis}^{1},\\Phi ^{1} )$, …, $(Y_{mis}^{N},\\Phi ^{N} )$ should be constructed. The missing data is estimated as$$ \\hat Y_{mis} &#x3D; \\frac{1}{N_{sample} - N_{burn-in}} \\sum_{t &#x3D; N_{burn-in + 1}}^{N_{sample}} Y_{mis}^t $$. The first $N_{burn-in}$ samples would be discarded. One feasible parameter setting is $N_{sample}&#x3D;1500$ and $N_{burn-in}&#x3D;500$. I believe the introduction of burn-in is to allow the model sometime to converge. PPCA-based imputation methodPPCA stands for Probabilistic Principal Component Analysis. It assumes that the observed data depends on latent varaiables $$ Y &#x3D; Wx + \\mu + \\epsilon $$ where $Y$ is a D-dimensional vector of observed data, $x$ is a q-dimensional latent varaible defined Gaussian distribution and $\\epsilon$ is isotropic noise. $x \\sim N(0,1)$, $\\epsilon \\sim N(0, \\sigma ^2 I)$ and $\\mu$ stands for a base mean value. Use Expectation Maximisation (EM) method to find a set of imputed data which best fit the above distribution. Concrete steps of EM method: Expectation E-step:Find out the expectation of completed log-likelihood function with previous estimated parameters $\\Phi ^k$ and observed data part $Y_{obs}$:$$ Q(\\Phi | \\Phi ^k) &#x3D; E_{X, Y_{mis} | Y_{obs}, \\Phi ^k}[log p_c (Y_c, X|\\Phi ^k)] $$We can use this to update our guess of the missing data part $Y_{mis}^k$ and latent data $X^k$. Maximisation M-step:Computiong parameter space $\\Phi$ by maximising the expectation of log-likelihood in E-step:$$ \\Phi ^{k+1} &#x3D; \\arg \\max_{\\Phi} Q(\\Phi | \\Phi ^k) $$ Conditional expectation $E[Y_{mis} | Y_{obs}, \\Phi]$ can be difficult to calculate and can approximate with MCMC with DA. Dataset Intended to Use: ComparisonPrediction and interpolation methods mentioned cannot capture stochastic variations in daily traffic flow. On the contrary, statistical learning methods could achieve traffic flow information by emphasising the statistical characteristics of traffic flow. Shorting coming of such methods: Cannot handle the situations in which neighbour (data points) DO NOT even exist.","categories":[{"name":"UCLA","slug":"UCLA","permalink":"https://umiao.github.io/categories/UCLA/"},{"name":"Course Study","slug":"UCLA/Course-Study","permalink":"https://umiao.github.io/categories/UCLA/Course-Study/"},{"name":"ECE209 in 2022 spring","slug":"UCLA/Course-Study/ECE209-in-2022-spring","permalink":"https://umiao.github.io/categories/UCLA/Course-Study/ECE209-in-2022-spring/"}],"tags":[{"name":"DataScience","slug":"DataScience","permalink":"https://umiao.github.io/tags/DataScience/"},{"name":"UCLA","slug":"UCLA","permalink":"https://umiao.github.io/tags/UCLA/"}]},{"title":"SQL-Study-Note-8 - Data Type of MySQL","slug":"SQL-Study-Note-8","date":"2022-04-17T05:47:13.000Z","updated":"2022-04-20T22:19:31.193Z","comments":true,"path":"2022/04/16/SQL-Study-Note-8/","link":"","permalink":"https://umiao.github.io/2022/04/16/SQL-Study-Note-8/","excerpt":"Data Type of MySQL Suggestion for Data Type Selection","text":"Data Type of MySQL Suggestion for Data Type Selection VARCHAR: For short string set to 50, for long string set to 255. Maximum length is 65535, 64KB. (Note that Char Type is fix-lengthed). MEDIUMTEXT: 16M document &#x2F; LONGTEXT: 4GB document &#x2F; TINYTEXT: 255 Bytes &#x2F; TEXT: equal to VARCHAR, 64KB Note that Chinese charcter takes 3 Byte each, so we allocate $3n$ Bytes to string with length of $n$ (pick the upper bound). Integer Type: TINYINT: 1 Byte, UNSIGNED TINYINT and SMALLINT : 2 Byte, MEDIUMINT: 3 Bytes, INT: 4 Bytes, BIGINT: 8 Bytes. Leading zero filling is supported: INT(4) -&gt; ‘0003’ Float Type: DECIMAL(p,s) defines the int length and decimal length, it can be viewed as a fixed-point decimal (int). DECIMAL &#x3D; DEC &#x3D; NUMERIC &#x3D; FIXED FLOAT: 4 Bytes, DOUBLE: 8 Bytes (Expressed in exponential form) Boolean: BOOL &#x2F; BOOLEAN, 1 bit Enumerate Type: ENUM(‘a’, ‘b’, ‘c’): value must be selected from the given set. This is not a good design as it is complex to change the domain of legal values, you may even need to rebuild the entire table. It is not reusable itself. Creating a table to store the mapping relationship is recommended. Time: Timestamp can only store date up to 2038 AD as it takes 4 Bytes. To store later time, use Datastamp. BLOB for Binary Large Object: TINYBLOB &#x2F; BLOB &#x2F; MEDIUMBLOB &#x2F; LONGBLOB takes 255 Bytes &#x2F; 65KB &#x2F; 16 MB &#x2F; 4 GB, respectively. Store files in the FileSystem as possible rather than store them in the database. Otherwise, you may come into problems like high memory usage, slow copying, low performance, indirect and complicated IO, etc. JSON: In order to set JSON object, you can use string form like: ‘{ “k”:v}’. You can also create the object with function:.1JSON_OBJECT(&#x27;weight&#x27;, 10, &#x27;dimensions&#x27;, JSON_ARRAY(1, 2, 3)); In order to extract the attributes included in JSON, you can use 12345678JSON_EXTRACT(properties, ‘$.weight’);-- while the properties stand for the desired column name / key of the JSON object. JSON_EXTRACT(properties, ‘$.weight.data.sub.time’);-- You can use multiple dots to get the nested attributes.properties -&gt; ‘$.weight’; -- Semi-CPP syntax is also supportedproperties -&gt; ‘$.weight[idx]’;-- Can specify a certain element of the JSON list use &#x27;[]&#x27; At the same time, it should be noted that the returned results are still in JSON format. 1234properties -&gt; ‘$.weight’;-- would return something like &quot;sony&quot;, which leads to problem when comparing with other resultsproperties -&gt;&gt; ‘$.weight’;-- is able to return sony, without &quot;&quot; In terms of updating partial attributes, you can use JSON_SET. Here SET stands for the motion of setting. 123SET properties = JSON_SET / JSON_REMOVE(properties, ‘$.weight’, 30, ‘$.age’, 10) WHERE id=1-- JSON_REMOVE is used to remove attributes The above example can be used to set part of the attributes in JSON object properties.","categories":[{"name":"Data Science","slug":"Data-Science","permalink":"https://umiao.github.io/categories/Data-Science/"},{"name":"SQL","slug":"Data-Science/SQL","permalink":"https://umiao.github.io/categories/Data-Science/SQL/"},{"name":"Job Search","slug":"Job-Search","permalink":"https://umiao.github.io/categories/Job-Search/"},{"name":"SQL","slug":"Job-Search/SQL","permalink":"https://umiao.github.io/categories/Job-Search/SQL/"}],"tags":[{"name":"DataScience","slug":"DataScience","permalink":"https://umiao.github.io/tags/DataScience/"},{"name":"SQL","slug":"SQL","permalink":"https://umiao.github.io/tags/SQL/"}]},{"title":"SQL-Study-Note-7 - Transactions","slug":"SQL-Study-Note-7","date":"2022-04-17T05:07:50.000Z","updated":"2022-04-17T05:47:05.601Z","comments":true,"path":"2022/04/16/SQL-Study-Note-7/","link":"","permalink":"https://umiao.github.io/2022/04/16/SQL-Study-Note-7/","excerpt":"Transactions Principles of Transaction (ACID) Atomicity Consistency Isolation Durability","text":"Transactions Principles of Transaction (ACID) Atomicity Consistency Isolation Durability 12345START TRANSACTION;// Instruction block to be executed-- If only part of the transaction is done and the connection to server is lost, the finished part would be rolled backCOMMIT; A transaction would lock the lines and tables to be updated so that they are untouchable to other transactions.If one transaction comes into locked resources, it would wait the owner of the lock to finish, or until it expires the time limit itself.At the same time, ROLLBACK is also a SQL instruction and keyword. Different level of transaction isolation: 12SET TRANSACTION ISOLATION LEVEL SERIALIZABLE;-- Note that this setting is session-leveled. It comes with the tradeoff that the higher the isolation level is, the lower performance it reaches. (In extreme situation, serializable level would not benefit from distributed architecture.) Read Uncommitted: May read uncommited data (dirty read). Rarely used in actual application as the performance improvement is very limited. Read Committed: Default level for most DBMS (Oracle, SQL server). However, it may counter Nonrepeatable Read: same select may have different result within one transaction. This is due to the UPDATE operation made by other transactions and can be solved by Line Level Lock. Repeatable Read: Applied with Line Level Lock. However, it can still encounter Phantom Reads (caused by the delete &#x2F; insert operations made by other transactions). Require Table Level Lock to solve. Serializable: Ban the parallel processing and sort all the transactions.","categories":[{"name":"Data Science","slug":"Data-Science","permalink":"https://umiao.github.io/categories/Data-Science/"},{"name":"SQL","slug":"Data-Science/SQL","permalink":"https://umiao.github.io/categories/Data-Science/SQL/"},{"name":"Job Search","slug":"Job-Search","permalink":"https://umiao.github.io/categories/Job-Search/"},{"name":"SQL","slug":"Job-Search/SQL","permalink":"https://umiao.github.io/categories/Job-Search/SQL/"}],"tags":[{"name":"DataScience","slug":"DataScience","permalink":"https://umiao.github.io/tags/DataScience/"},{"name":"SQL","slug":"SQL","permalink":"https://umiao.github.io/tags/SQL/"}]},{"title":"SQL-Study-Note-6 - Trigger and Events","slug":"SQL-Study-Note-6","date":"2022-04-17T04:46:07.000Z","updated":"2022-04-17T05:05:21.886Z","comments":true,"path":"2022/04/16/SQL-Study-Note-6/","link":"","permalink":"https://umiao.github.io/2022/04/16/SQL-Study-Note-6/","excerpt":"TriggerTriggers are the code blocks executed automatically before insertion &#x2F; update &#x2F; delete take effect.","text":"TriggerTriggers are the code blocks executed automatically before insertion &#x2F; update &#x2F; delete take effect. 123456789DELIMITER $$CREATE TRIGGER payments_after_insert AFTER/BEFORE INSERT/UPDATE/DELETE ON payments FOR EACH ROWBEGIN -- You can either write SQL codes here or call the existing procedure...END $$DELIMITER ; Extensive syntax123NEW -- Return the just inserted line.OLD -- Return the just deleted line.NEW.amount -- Can use . to specify a column These two (NEW &#x2F; OLD) are keywords of MySQL.Triggers can be used to modify data of any table EXCEPT the table which is being listened by the trigger. This is because trigger can trigger itself and results in infinite loop. 12SHOW TRIGGERS -- Show all the created triggers.ShOW TRIGGERS LIKE &#x27;c%&#x27; -- Filter the triggers. Triggers can be also used for auditing purpose, i.e., record the executor, attribute and timestamp when an operation is done. EVENTEvents are periodically triggered codes for multiple tasks. 12SHOW VARIABLES -- Show all system variables.SET GLOBAL event_scheduler=ON / OFF -- Switch the event_scheduler Create Event: 12345678DELIMITER $$CREATE EVENT yearly_delete_state_audit_rows ON SCHEDULEEVERY 1 YEAR STARTS ‘2020-01-01’ ENDS ’2029-01-01’DO BEGIN -- Note that DO is required here....END $$DELIMITER ; Two ways to calculate the diff of time: 12NOW() – INTERVAL 1 YEAR;DATESUB(NOW(), INTERVAL 1 YEAR); Activate &#x2F; Deactivate Events: 1ALTER EVENT e_name DISABLE;","categories":[{"name":"Data Science","slug":"Data-Science","permalink":"https://umiao.github.io/categories/Data-Science/"},{"name":"SQL","slug":"Data-Science/SQL","permalink":"https://umiao.github.io/categories/Data-Science/SQL/"},{"name":"Job Search","slug":"Job-Search","permalink":"https://umiao.github.io/categories/Job-Search/"},{"name":"SQL","slug":"Job-Search/SQL","permalink":"https://umiao.github.io/categories/Job-Search/SQL/"}],"tags":[{"name":"DataScience","slug":"DataScience","permalink":"https://umiao.github.io/tags/DataScience/"},{"name":"SQL","slug":"SQL","permalink":"https://umiao.github.io/tags/SQL/"}]},{"title":"SQL-Study-Note-5 - Stored Procedure and User Defined Functions","slug":"SQL-Study-Note-5","date":"2022-04-17T02:01:32.000Z","updated":"2022-04-17T04:48:52.424Z","comments":true,"path":"2022/04/16/SQL-Study-Note-5/","link":"","permalink":"https://umiao.github.io/2022/04/16/SQL-Study-Note-5/","excerpt":"Stored ProcedureMotivationGenerally, developers prefer not to interpret string as SQL codes &#x2F; instructions due to security concerns.","text":"Stored ProcedureMotivationGenerally, developers prefer not to interpret string as SQL codes &#x2F; instructions due to security concerns. You can wrap the query and update functionality with Stored Procedure. DBMS is able to further optimize the stored procedure and enhance the security. The stored procedure itself is similar to a function implementation. Syntax Implementation123456DELIMITER $$CREATE PROCEDURE get_clients()BEGIN SELECT * FROM clients;END $$DELIMITER ; The reason of changing DELIMITER is that, we need to use ; to seperate SQL statements within the stored procedure. (We are forced to do so!)This will damage the integrity of our BEGIN-END statement block. Thus, we should temporarily change the DELIMITER (into $$) and change back to ; after the definition of our stored procedure. In order to avoid conflict of naming, MySQL would add a pair of &#96; to the names of databases, tables and columns. 1Student -&gt; `Student` -- Auto-Renamed to avoid conflicts. You can use 1CALL procedure_name() to call the defined stored procedure. If you are using the workbench of MySQL, you can simply right click Store Procedures to create one. In this case you do not need to worry about the delimiter and MySQL would help you with the transformation (Some sort of Syntactic sugar). Delete Stored Procedure1DROP PROCEDURE (IF EXISTS) get_clients; Parameter Setting of Stored Procedure12CREATE PROCEDURE get_clinets ( state CHAR(2) );-- You must specify the size and type of the passed parameter. After setting the parameter declaration, the parameters can be then used in the procedure for program logic building.All the parameters are REQUIRED. However, they can have default values.Even if you want to use the default value, you should pass a NULL to the procedure as a placeholder. 123456IF state IS NULL THEN SET state = ‘CA’; END IF;-- By using such statement, you can realize default value de facto.table.col_name = IFNULL(para, table.col_name);-- This one is more concise and thus recommended.-- If para is NULL, then use the default value. Parameter Verification and Constraints12345IF payment_amount &lt;= 0 THEN SIGNAL SQLSTATE &#x27;22003&#x27; SET MESSAGE_TEXT = ‘Invalid payment amount’;END IF-- payment_amount is required to &gt; 0. If not satisfied, a error code of &#x27;22003&#x27; is raised and the prompting MESSAGE_TEXT is written. SIGNAL is similar to throw exception in other languages. SQLSTATE is the predetermined error code (corresponding to ‘out of range’ here, refer the documentation). Provide Return Value for Stored Procedure1234CREATE PROCEDURE `name` (client_id INT, OUT invoices_count INT)BEGIN SELECT COUNT(*) INTO invoices_count FROM invoices;END This is a syntactic sugar anyway. What MySQL actually does is define two parameters and pass them to the PROCEDURE for updating. Then SELECT the updated parameter.At the same time, MySQL uses a ‘@’ prefix to identify variables. For an example, 1SET @a = 0; User Variable and Local VariableSET is used to assign the User Variable while DECLARE is used to assign the Local Variable used within a stored procedure. 1DECLARE risk_factor DECIMAL(9, 2) DEFAULT 0; You can assign the declared variable with the following code: 1SELECT COUNT(*) INTO risk_factor FROM table; User-Defined FunctionsThe only difference between the procedure and function is that function can only return one single value. 12345678CREATE FUNCTION get_risk_f ( client_id INT) -- Must specify the type for the input parameterRETURNS INTEGER -- The return parameter must have a type too. Function always returns a single value rather than a query result.DETERMINISTIC -- Optional attribute. Always return the same result for the same id.READS SQL DATA -- Optional. This function can read SQLMODIFIES SQL DATA -- Optional. This function can modify table.BEGIN...RETURN 1; Functions can be deleted with DROP keyword as well.","categories":[{"name":"Data Science","slug":"Data-Science","permalink":"https://umiao.github.io/categories/Data-Science/"},{"name":"SQL","slug":"Data-Science/SQL","permalink":"https://umiao.github.io/categories/Data-Science/SQL/"},{"name":"Job Search","slug":"Job-Search","permalink":"https://umiao.github.io/categories/Job-Search/"},{"name":"SQL","slug":"Job-Search/SQL","permalink":"https://umiao.github.io/categories/Job-Search/SQL/"}],"tags":[{"name":"DataScience","slug":"DataScience","permalink":"https://umiao.github.io/tags/DataScience/"},{"name":"SQL","slug":"SQL","permalink":"https://umiao.github.io/tags/SQL/"}]},{"title":"SQL-Study-Note-4 - View","slug":"SQL-Study-Note-4","date":"2022-04-17T01:39:43.000Z","updated":"2022-04-17T02:00:31.084Z","comments":true,"path":"2022/04/16/SQL-Study-Note-4/","link":"","permalink":"https://umiao.github.io/2022/04/16/SQL-Study-Note-4/","excerpt":"ViewIntroduction to ViewWith the introduction of View, middle &#x2F; query results can be stored for further query and use, just like a real table.","text":"ViewIntroduction to ViewWith the introduction of View, middle &#x2F; query results can be stored for further query and use, just like a real table. Creation and Manipulation on View Creation of View: 1CREATE VIEW view_name AS (SELECT …) Created Views would NOT be stored with the tables. It would be stored in ‘Views’ instead. Alter &#x2F; Drop of View: 1234DROP VIEW sales_by_client;-- Drop / delete Operation.CREATE / REPLACE VIEW AS ...;-- REPLACE has the advantage against CREATE that it does not require the view to be dropped in advance. Created Views would NOT be stored with the tables. It would be stored in ‘Views’ instead. In fact, the Views should be viewed as stored query code. When you need to use them, you can simply rerun the script to retrieve the result. So you can use version control tools to store and share them. Updatable Views: Updatable Views stand for those Views who DO NOT contain the keywords of DISTINCT &#x2F; aggregate functions &#x2F; GROUP BY &#x2F; HAVING &#x2F; UNION. In this case, these Views can be updated via CREATE &#x2F; REPLACE. Update Opertion: 1UPDATE view_name SET due_date = DATE_ADD(due_date, INTERVAL 2 DAY) WHERE invoice_id = 1l Point of updatable views: If you DO NOT have the authorization to modify a table, you can still create a View based on that table and update the View, as long as it is Updatable. WITH CHECK OPTION: If the UPDATE operation may cause some rows to be deleted, you can add WITH CHECK OPTION to the end of the UPDATE code to prevent this from happening.","categories":[{"name":"Data Science","slug":"Data-Science","permalink":"https://umiao.github.io/categories/Data-Science/"},{"name":"SQL","slug":"Data-Science/SQL","permalink":"https://umiao.github.io/categories/Data-Science/SQL/"},{"name":"Job Search","slug":"Job-Search","permalink":"https://umiao.github.io/categories/Job-Search/"},{"name":"SQL","slug":"Job-Search/SQL","permalink":"https://umiao.github.io/categories/Job-Search/SQL/"}],"tags":[{"name":"DataScience","slug":"DataScience","permalink":"https://umiao.github.io/tags/DataScience/"},{"name":"SQL","slug":"SQL","permalink":"https://umiao.github.io/tags/SQL/"}]},{"title":"SQL Study Note - 3 - Function and the Aggregate Function","slug":"SQL-Study-Note-3","date":"2022-04-17T01:34:31.000Z","updated":"2022-04-17T01:48:08.598Z","comments":true,"path":"2022/04/16/SQL-Study-Note-3/","link":"","permalink":"https://umiao.github.io/2022/04/16/SQL-Study-Note-3/","excerpt":"Function and the Aggregate Function","text":"Function and the Aggregate Function Aggregate Function: 1COUNT(), MAX(), MIN(), AVG(), SUM() It should be noted that COUNT(row_name) only returns the number of the non-empty records. If you need to find out the total number of rows, you shoud use COUNT(*). You can use COUNT (DISTINCT client_id) to find out the number of unique client_id, too. Non-Aggregate Function: 1234RAND() -- Generate a random number within (0, 1)RAND(seed) -- Specify the rand seedSQRT() -- Find the square root for each valueCONCAT(a, b) -- Concat two strings into one Non-aggregate function would return a same-lengthed sequence for the input values. These functions are element-wised. GROUP BY clause: Group the rows according to a given column name. Rows with the same value in the very column would be aggregated together. The order of query clause: IMPORTANT: SELECT -&gt; FROM -&gt; WHERE -&gt; ORDER BY Grouping based on multiple attributes: 1GROUP BY state, city In this case, the grouping would based on the tuple: (state, city) Having: 1SELECT SUM(res) AS aggregated_res FROM t GROUP BY state HAVING aggregated_res &gt; 100; You cannot use WHERE clause to filter the result of the aggreate function, because at that time, the query is not yet completed and the aggregate result is not yet calculated. It should be noted that HAVING clause supports the filtering on Composite Condition, e.g. HAVING aggre_res1 &gt; 10 AND aggre_res2 &lt; 10. The HAVING clause is execute after the query is finished. So that it can only filter the selected columns. The columns not selected cannot be used in the filtering constraint. HAVING does NOT support alias. WITH ROLLUP: 1SELECT SUM(res) AS aggregated_res FROM t GROUP BY state HAVING aggregated_res &gt; 100; Conduct an extra aggregate operation for all the aggregated results. E.g., the SUM &#x2F; MEAN of the aggregated results. This is only supported by MySQL. If composite grouping is applied, e.g., GROUP BY col_a, col_b, each group identified by a unique (col_a, col_b) would conduct an extra aggregation. Nesting Sub-query: 12SELECT * FROM (SELECT ...);SELECT * FROM table WHERE col_name IN / NOT IN (SELECT ...); I.E., select from the result of another select operation. ALL VS ANY &#x2F; SOME 1234SELECT * FROM invoices WHERE invoice_total &gt; ALL(SELECT invoice_total FROM invoices WHERE client_id = 3);-- Require the records to be greater than ANY of the sub-query results in order to be selectedSELECT * FROM invoices WHERE invoice_total &gt; ANY / SOME(SELECT invoice_total FROM invoices WHERE client_id = 3);-- Require the records to be greater than ONE of the sub-query results in order to be selected ANY &#x2F; SOME are completely equivalent. If one value of the sub-query satisfies the logical expression, the ‘&gt; ANY’ expression is satisfied. For ALL, only if all the values of the sub-query satisfies the logical expression, the ‘&gt; ALL’ expression can be satisfied. ‘&#x3D; ANY’ also equals to ‘IN’. Correlated sub-query Code-writing Order: SELECT, FROM, WHERE, GROUP BY, HAVING, ORDER BY Executing Order: FROM, WHERE, GROUP BY, HAVING, SELECT, ORDER BY The marked line is crucial, as the logic of correlated subquery would retrive one value from the main query at a time, working in an iterative manner, input the value into the sub-query to ge the result and pass the result back to the main query. The main query would check the constraint of WHERE clause and return the result; This means that different alias are required even they points to the same table. Sub-query can touch the alias of the main &#x2F; outer query. EXISTS 1SELECT * FROM c WHERE EXISTS (SELECT id FROM I WHERE c_id = c.c_id) EXISTS keyword has advantage against the ‘IN (sub-query)’ manner. This is because the ‘IN (sub-query)’ needs to finish the sub-query first before the sub-query can return any result to the outer query. However, EXISTS can work as a short-circuiting operator which stops immediately when the first results is found. Write Sub-query in SELECT &#x2F; FROM clause Use SELECT to duplicate the result of aggregate function1SELECT (SELECT AVG() FROM t) AS average FROM t; This query makes sense because, the aggregate function would only return one single value. If you want to conduct row-wise calculation on the aggregate value, you have to duplicate it. You can also SELECT FROM a sub-query like it is a real-table. However, an alias is required. This may make the query too complicated and should be used with care. Numerical Function123456789ROUND(num, mantissas_n); -- Round the given number, and mantissas_n decimal places are preserved.TRUNCATE(num, mantissas_n); -- Truncate the given number with the decimal setting.--Simiarly, we have:CEILING()FLOOR()ABS()RAND() Other available functions can be found in the MySQL documentation. String Function1234567891011121314151617181920LENGTH(&#x27;sky&#x27;); -- Return the length of the input string.UPPER(&#x27;sky&#x27;);--transform to upper caseLOWER(&#x27;sky&#x27;);--transform to lower caseLTRIM() / RTRIM() / TRIM();-- Remove the left / right / both side of spaces.LEFT(string, n);-- Return the left n chars;RIGHT(string, n);-- Return the right n chars;SUBSTRING(string, start, n);-- Return n chars starts from start.LOCATE(&#x27;n&#x27;, &#x27;kinter&#x27;);-- Find the smallest index where the pattern (&#x27;n&#x27;) occurs in the searched string (&#x27;kinter&#x27;). Index starts from 1.REPLACE(string, source, target);-- Replace all the pattern of source to target, in string.CONCAT(a, b);-- Concat strings into 1. Refer the documentation for more string functions. Time Function1234567891011121314NOW();-- Return the current time and date.CURDATE();-- Return the current date.CURTIME():-- Return the current time.YEAR(time) / MONTH() / DAY() / HOUR() / MINUTE() / SECOND() ...-- Extract the year... of a time / date. DAYNAME(time);-- Return the name of day, like FridayMONTHNAME(time);-- Return sth like DECEMBER...EXTRACT( YEAR FROM NOW() )-- Personalize a date / time.. Year can be substitute with other keywords E.g., extract order of this year: YEAR(date) &#x3D; YEAR(NOW()); Fomat Time &#x2F; Date123456789101112DATE_FORMAT(NOW(), &#x27;%y&#x27;);-- %y for 2-digit year, and %Y for 4-digit year;-- Similar for D/d/M/m, ...-- Can be use to format time as well.SELECT DATE_ADD( NOW(), INTERVAL 1 DAY );-- Return the date of 1 day later. Accept negative value like -1.-- Can Use DATE_SUB instead and the behavior is very similar.DATEDIFF(d_1, d_2);-- Find the diff of two dates. (by days, the input accepts DATE only)-- Result can be negative, calculated by d_1 - d_2.TIME_TO_SEC(time);-- Transform time to second, starts from 12 am. IFNULL &amp; COALESCE123SELECT order_id IFNULL(shipper_id, &#x27;Not Assigned&#x27;) AS s;-- If a shipper_id is NULL, return &#x27;Not Assigned&#x27; instead.COALESCE(shipper_id, comments, ..., &#x27;Not assigned&#x27;); The COALESCE is the generalization of IFNULL. The principle is, by offering a bunch of column_name &#x2F; values, return the first one which IS NOT NULL. IF &#x2F; CASE (Conditional Statement)1234567891011IF (expression, first, second);-- If the expression is TRUE, then return first; else, return second.SELECT order_id CASE WHEN YEAR(order_date) = YEAR(NOW()) THEN ‘Active’ WHEN YEAR(order_date) = YEAR(NOW()) - 1 THEN ‘Last Year’ ELSE ‘Other cases’END AS categoryFROM orders-- The case statement is quite similar with IF statement.","categories":[{"name":"Data Science","slug":"Data-Science","permalink":"https://umiao.github.io/categories/Data-Science/"},{"name":"SQL","slug":"Data-Science/SQL","permalink":"https://umiao.github.io/categories/Data-Science/SQL/"},{"name":"Job Search","slug":"Job-Search","permalink":"https://umiao.github.io/categories/Job-Search/"},{"name":"SQL","slug":"Job-Search/SQL","permalink":"https://umiao.github.io/categories/Job-Search/SQL/"}],"tags":[{"name":"DataScience","slug":"DataScience","permalink":"https://umiao.github.io/tags/DataScience/"},{"name":"SQL","slug":"SQL","permalink":"https://umiao.github.io/tags/SQL/"}]},{"title":"SQL Study Note - 2 - The Update / Delete / Insert Syntax","slug":"SQL-Study-Note-2","date":"2022-04-17T01:29:50.000Z","updated":"2022-04-17T01:48:03.088Z","comments":true,"path":"2022/04/16/SQL-Study-Note-2/","link":"","permalink":"https://umiao.github.io/2022/04/16/SQL-Study-Note-2/","excerpt":"The update &#x2F; delete &#x2F; insert syntax","text":"The update &#x2F; delete &#x2F; insert syntax The column attributes of table: PK： primary key NN： Not Null UQ：Unique Index B： binary UN： unsigned data type ZF： zero filled AI： Auto incremental G： Generated column Data Type in MySQL: INT (11): integer with a length of 11 VARCHAR(50): array of char with a size $\\le 50$. CHAR(50): array of char with a size $&#x3D; 50$. DEFAULT: Use the given default value to fill this column. Insert data to table: 1INSERT INTO customers VALUES (DEFAULT, ‘John’, ‘Smith’, ‘1990-01-01’, NULL, ‘address’, ‘city’, ‘CA’, DEFAULT); At the same time, MySQL allows to specify the column names to be assigned values. 1INSERT INTO customers (first_name, …, state, points) VALUES (…); In this case, you do not need to assign the values to the order (of columns) defined by the table. The number of affected rows would be returned after successful insertion. Insert Multi-rows: 1INSERT INTO shippers (name) VALUES (&#x27;S1&#x27;), (&#x27;S2&#x27;), (&#x27;S3&#x27;); LAST_INSERT_ID: Returns the most recently generated Auto Incremental ID. Enable hierarchical data insertion. I.E., find the ID of the latest inserted data, and then use the id to associate &#x2F; update other tables. This syntax feature can eliminate ambiguity, and it is also convenient to correspond a main table record to multiple sub table records. Duplicate Table: 1CREATE TABLE orders_archived AS SELECT * FROM orders; Use the selected partial &#x2F; entire data of other table to create a duplicate. However, column attributes (constraints) like PK, AI would be ignored. Batch Insertion with Select: 1INSERT INTO orders_archived SELECT * FROM orders WHERE order_date &lt; ’2019-01-01’; Column attributes (constraints) like PK, AI would be ignored as well. Truncate Table in workbench: Right click a table and select ‘truncate table’ would remove all the data (records) but would not remove the table itself. Update a single row: 1UPDATE invoices SET payment_total = 10, payment_date=’2019-03-01’ WHERE invoice_id = 1; Filter the results (single line) that meet the conditions and update the filtered results. It is also allowed to use default, arithmetic expression, etc. as the new value of the selected row. Note that even if multiple statements are selected for your filter criteria, MySQL workbench runs in the security update mode by default, allowing you to update only one row at a time. However, in other environments, there is no such problem. You can drag it to the bottom of SQL editor and choose to uncheck the safe updates option. After changing the settings, you need to reconnect for the settings to take effect. WHERE attribute IN (1,2,3) can be used to filter multiple records. Use SELECT to UPDATE (apply sub-query in UPDATE): 1UPDATE invoices SET payment_total = 10, payment_date=’2019-03-01’ WHERE client_id = ( SELECT client_id FROM clients WHERE name=’Myworks’ ); In this manner, a single logical judgement is replaced with a sub-query to update multiple values at a time. If multiple values would be returned in your sub-query, the WHERE clause should be changed to WHERE client_id IN (sub-query). You should test the sub-query before update the table. You CANNOT update the same table where you conduct your sub-query —- If you have to do so, create a duplicate and give it an alias. DELETE:1DELETE FROM invoices WHERE (invoice_id=1); Obviously, the condition within the parenthesis can be a sub-query, too. Rebuild the Database:12DROP DB If EXISTS DB;-- Conduct the script of DB building then.","categories":[{"name":"Data Science","slug":"Data-Science","permalink":"https://umiao.github.io/categories/Data-Science/"},{"name":"SQL","slug":"Data-Science/SQL","permalink":"https://umiao.github.io/categories/Data-Science/SQL/"},{"name":"Job Search","slug":"Job-Search","permalink":"https://umiao.github.io/categories/Job-Search/"},{"name":"SQL","slug":"Job-Search/SQL","permalink":"https://umiao.github.io/categories/Job-Search/SQL/"}],"tags":[{"name":"DataScience","slug":"DataScience","permalink":"https://umiao.github.io/tags/DataScience/"},{"name":"SQL","slug":"SQL","permalink":"https://umiao.github.io/tags/SQL/"}]},{"title":"SQL Study Note - 1 - Syntax Basics","slug":"SQL-Study-Note-1","date":"2022-04-16T21:05:53.000Z","updated":"2022-04-17T01:31:33.088Z","comments":true,"path":"2022/04/16/SQL-Study-Note-1/","link":"","permalink":"https://umiao.github.io/2022/04/16/SQL-Study-Note-1/","excerpt":"Overview The core of database system is to interact with DB (DataBase) with DBMS (Database Management System).","text":"Overview The core of database system is to interact with DB (DataBase) with DBMS (Database Management System). The DB can be generally divided into: Relational DB NoSQL DB (e.g., KV (key-value) based DB) Recommended code style of SQL (Structed Query Language): Capitalize all keywords and reserved words, and lowercase all other contents. Each statement should end with ;. Keywords and Syntax RulesThe query syntax SHOW DATABASES 1SHOW DATABASES; List all the names of exisitng databases (under the current schema). USE 1234USE database_name;SELECT * from table;SELECT * from database_name.table; -- Must specify the database_name for the DBs which are not in use Select one DB as the default one. SELECT 1SELECT (column_name) FROM (table_name) WHERE (condition) ORDER BY (col_name). Select the desired data from a table. It should be noted that you should use &#x3D; in SQL to determine equivalence. (It DOES NOT mean assignment.) You can conduct calculation on the selected result. AS 1SELECT (column_name) FROM (table_name) WHERE (condition) ORDER BY (col_name). For each col_name, table_name to be queried and the queried results, you can always to set alias (surname) for them with AS. – &#x2F; comment 12-- This a comment.// This is also acceptable. DISTINCT 1SELECT DISTINCT column_name FROM t Add DISTINCT ahead of the queried target (column) to receive all the unique values. AND &#x2F; OR &#x2F; NOT 1SELECT * FROM t WHERE col_a &gt; 10 and col_b = &#x27;CA&#x27; Logical operator to be used with the WHERE clause. IN 1SELECT * FROM t WHERE col_a IN (&#x27;A&#x27;, &#x27;B&#x27;) Determine if the queried value belongs to a set. BETWEEN 123SELECT * FROM t WHERE point BETWEEN 100 AND 300;SELECT * FROM t WHERE point &gt;= 100 AND point &lt;= 300;-- These two are equivalent Determine if the queried value within a given interval. Both ends of the interval are closed ([beg, end]). LIKE12SELECT * FROM t WHERE name like &#x27;b%&#x27;-- Able to match &#x27;Bob&#x27; and &#x27;bike&#x27; Provide functionality similar to Regular Expression. % can match arbitrary string, _ can match arbitrary char. Not sensitive to the case. REGEXP1SELECT * FROM t WHERE name REGEX &#x27;^f[a-z]+d&#x27; Match a given Regular Expression pattern. IS NULL12SELECT * FROM t WHERE name IS NULL;SELECT * FROM t WHERE name IS NOT NULL; Query all the records which are (not) null in a given column. ORDER BY1SELECT * FROM t ORDER BY col_name DESC / AESC Decide the sorting order of the returned records. LIMIT12SELECT * FROM t LIMIT offset, tot_numSELECT * FROM t LIMIT tot_num Restrict the number of the returned records. Skip the first $n&#x3D;$offset records and then return tot_num lines of records. Return all the records if number of matched records fewer than tot_num. INNER JOIN123SELECT * FROM t_a JOIN t_b on t_a.col_1 = t_b.col_2;SELECT * FROM t_a JOIN t_b on t_a.col_1 = DB_2.t_b.col_2;-- You can conduct crossed-DB join by specifying the name of the DB not in use. Can be simply writtene as JOIN. Concat two tables based on the given condition. Conduct Cartesian product implicitly. SELF JOIN1SELECT * FROM t_a AS a JOIN t_a AS b on a.col_1 = b.col_2; A table can join with itself, but different alias are required. Multi-table JOIN1SELECT * FROM t_a JOIN t_b on a.col_1 = b.col_2 JOIN t_c on b.col_2 = c.col_3; Multiple (n) tables can be joined but this is not recommended when $ n &gt; 3 $ due to performance concern. Composite JOIN &#x2F; Implicit JOIN1SELECT * FROM t_a JOIN t_b on a.col_1 = b.col_2 JOIN t_c on b.col_2 = c.col_3; Sometimes only a tuple of multiple attributes can uniquely identify a row of the table. In this case, these attributes become Composite Primary Key. 1SELECT * FROM t_a, t_b; Implicit JOIN is conducted in the above example but this is not recommended, too. OUTER JOIN1SELECT * FROM t_a AS a JOIN t_b AS b on a.col_1 = b.col_2 JOIN t_c AS c on b.col_2 = c.col_3; When using INNER JOIN, some records of the left table cannot match with the right table because the condition of the ON clause is not satisfied. However, if we want to return all the records of the left (right) table regardless of the boolean value of the ON clause, we can use LEFT (RIGHT) OUTER JOIN. You should use RIGHT JOIN instead of LEFT JOIN as possible. SELF OUTER JOIN is similar, and alias is still required. USING123SELECT * FROM t_a JOIN t_b on t_a.col_1 = t_b.col_1;SELECT * FROM t_a JOIN t_b USING (col_1);-- These two are equivalent. Can be used to simplify the code, if the column names of the to-be-joined tables are exactly the same. You can Join on a tuple like ‘USING (id1, id2, id3)’ and these column names should be exactly the same as well (in the two tables). NATURAL JOIN1SELECT * FROM t_a NATURAL JOIN t_b; Let the compiler (DBMS) to decide the way of join. Not recommended to use! CROSS JOIN1SELECT * FROM t_a CROSS JOIN t_b; Conduct Cartesian Product. UNION1SELECT * FROM a UNION SELECT * FROM b; Concatenate multiple queried results together (on the direction of row). The column names should be exactly the same. IT SHOULD BE NOTED that ORDER BY can be set only once, so union all the results before setting the ORDER clause.","categories":[{"name":"Data Science","slug":"Data-Science","permalink":"https://umiao.github.io/categories/Data-Science/"},{"name":"SQL","slug":"Data-Science/SQL","permalink":"https://umiao.github.io/categories/Data-Science/SQL/"},{"name":"Job Search","slug":"Job-Search","permalink":"https://umiao.github.io/categories/Job-Search/"},{"name":"SQL","slug":"Job-Search/SQL","permalink":"https://umiao.github.io/categories/Job-Search/SQL/"}],"tags":[{"name":"DataScience","slug":"DataScience","permalink":"https://umiao.github.io/tags/DataScience/"},{"name":"SQL","slug":"SQL","permalink":"https://umiao.github.io/tags/SQL/"}]}],"categories":[{"name":"Data Science","slug":"Data-Science","permalink":"https://umiao.github.io/categories/Data-Science/"},{"name":"General Knowledge","slug":"Data-Science/General-Knowledge","permalink":"https://umiao.github.io/categories/Data-Science/General-Knowledge/"},{"name":"SQL","slug":"Data-Science/SQL","permalink":"https://umiao.github.io/categories/Data-Science/SQL/"},{"name":"Job Search","slug":"Job-Search","permalink":"https://umiao.github.io/categories/Job-Search/"},{"name":"SQL","slug":"Job-Search/SQL","permalink":"https://umiao.github.io/categories/Job-Search/SQL/"},{"name":"UCLA","slug":"UCLA","permalink":"https://umiao.github.io/categories/UCLA/"},{"name":"Course Study","slug":"UCLA/Course-Study","permalink":"https://umiao.github.io/categories/UCLA/Course-Study/"},{"name":"ECE209 in 2022 spring","slug":"UCLA/Course-Study/ECE209-in-2022-spring","permalink":"https://umiao.github.io/categories/UCLA/Course-Study/ECE209-in-2022-spring/"}],"tags":[{"name":"DataScience","slug":"DataScience","permalink":"https://umiao.github.io/tags/DataScience/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://umiao.github.io/tags/Machine-Learning/"},{"name":"SQL","slug":"SQL","permalink":"https://umiao.github.io/tags/SQL/"},{"name":"UCLA","slug":"UCLA","permalink":"https://umiao.github.io/tags/UCLA/"}]}